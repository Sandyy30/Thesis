{'accelerator': 'gpu',
 'accumulate_grad_batches': 1,
 'annotation': 'data/iu_xray/annotation.json',
 'base_dir': './data/iu_xray/images',
 'batch_size': 8,
 'beam_size': 3,
 'ckpt_file': None,
 'dataset': 'iu_xray',
 'delta_file': None,
 'devices': 1,
 'diversity_penalty': 0,
 'do_sample': False,
 'end_sym': '</s>',
 'every_n_train_steps': 0,
 'freeze_vm': True,
 'global_only': False,
 'gradient_clip_val': None,
 'learning_rate': 0.0001,
 'length_penalty': 2.0,
 'limit_test_batches': 1.0,
 'limit_train_batches': 1.0,
 'limit_val_batches': 1.0,
 'llama_model': 'TinyLlama/TinyLlama-1.1B-Chat-v1.0',
 'llm_alpha': 16,
 'llm_r': 16,
 'llm_use_lora': False,
 'lora_dropout': 0.1,
 'low_resource': False,
 'max_epochs': 15,
 'max_length': 60,
 'max_new_tokens': 100,
 'min_new_tokens': 40,
 'no_repeat_ngram_size': 2,
 'num_beam_groups': 1,
 'num_nodes': 1,
 'num_sanity_val_steps': 0,
 'num_workers': 8,
 'precision': 'bf16-mixed',
 'prefetch_factor': 4,
 'repetition_penalty': 2.0,
 'savedmodel_path': './save/iu_xray/v1_shallow',
 'scorer_types': ['Bleu_4', 'CIDEr'],
 'strategy': 'auto',
 'temperature': 0,
 'test': False,
 'test_batch_size': 16,
 'val_batch_size': 12,
 'val_check_interval': 1.0,
 'validate': False,
 'vis_alpha': 16,
 'vis_r': 16,
 'vis_use_lora': False,
 'vision_model': 'microsoft/swin-base-patch4-window7-224',
 'weights': [0.5, 0.5]}
Global seed set to 42
Using bfloat16 Automatic Mixed Precision (AMP)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
Loading vision encoder:microsoft/swin-base-patch4-window7-224
/home/sandy/miniconda3/envs/success/lib/python3.9/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Some weights of the model checkpoint at microsoft/swin-base-patch4-window7-224 were not used when initializing SwinModel: ['classifier.weight', 'classifier.bias']
- This IS expected if you are initializing SwinModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing SwinModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Loading Frozen vision encoder:microsoft/swin-base-patch4-window7-224 -- Done
Loading LLAMA
Some weights of LlamaForCausalLM were not initialized from the model checkpoint at TinyLlama/TinyLlama-1.1B-Chat-v1.0 and are newly initialized: ['model.layers.10.self_attn.rotary_emb.inv_freq', 'model.layers.21.self_attn.rotary_emb.inv_freq', 'model.layers.8.self_attn.rotary_emb.inv_freq', 'model.layers.18.self_attn.rotary_emb.inv_freq', 'model.layers.16.self_attn.rotary_emb.inv_freq', 'model.layers.1.self_attn.rotary_emb.inv_freq', 'model.layers.5.self_attn.rotary_emb.inv_freq', 'model.layers.7.self_attn.rotary_emb.inv_freq', 'model.layers.9.self_attn.rotary_emb.inv_freq', 'model.layers.14.self_attn.rotary_emb.inv_freq', 'model.layers.6.self_attn.rotary_emb.inv_freq', 'model.layers.17.self_attn.rotary_emb.inv_freq', 'model.layers.3.self_attn.rotary_emb.inv_freq', 'model.layers.13.self_attn.rotary_emb.inv_freq', 'model.layers.15.self_attn.rotary_emb.inv_freq', 'model.layers.11.self_attn.rotary_emb.inv_freq', 'model.layers.20.self_attn.rotary_emb.inv_freq', 'model.layers.4.self_attn.rotary_emb.inv_freq', 'model.layers.2.self_attn.rotary_emb.inv_freq', 'model.layers.12.self_attn.rotary_emb.inv_freq', 'model.layers.0.self_attn.rotary_emb.inv_freq', 'model.layers.19.self_attn.rotary_emb.inv_freq']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of LlamaForCausalLM were not initialized from the model checkpoint at TinyLlama/TinyLlama-1.1B-Chat-v1.0 and are newly initialized because the shapes did not match:
- model.layers.0.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.0.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.1.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.1.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.10.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.10.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.11.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.11.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.12.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.12.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.13.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.13.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.14.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.14.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.15.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.15.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.16.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.16.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.17.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.17.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.18.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.18.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.19.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.19.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.2.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.2.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.20.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.20.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.21.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.21.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.3.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.3.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.4.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.4.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.5.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.5.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.6.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.6.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.7.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.7.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.8.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.8.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.9.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.9.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Loading LLAMA Done
You are using a CUDA device ('NVIDIA GeForce RTX 3060 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.
Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.
Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name           | Type             | Params
----------------------------------------------------
0 | visual_encoder | SwinModel        | 86.7 M
1 | llama_model    | LlamaForCausalLM | 1.3 B 
2 | embed_tokens   | Embedding        | 65.5 M
3 | llama_proj     | Linear           | 2.1 M 
4 | layer_norm     | LayerNorm        | 4.1 K 
----------------------------------------------------
2.1 M     Trainable params
1.3 B     Non-trainable params
1.4 B     Total params
5,401.502 Total estimated model params size (MB)
Training: 0it [00:00, ?it/s]Training:   0%|          | 0/258 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/258 [00:00<?, ?it/s] Epoch 0:   0%|          | 1/258 [00:14<1:01:28, 14.35s/it]Epoch 0:   0%|          | 1/258 [00:14<1:01:29, 14.36s/it, v_num=1, loss=10.60]Epoch 0:   1%|          | 2/258 [00:22<48:56, 11.47s/it, v_num=1, loss=10.60]  Epoch 0:   1%|          | 2/258 [00:23<50:44, 11.89s/it, v_num=1, loss=9.870]Epoch 0:   1%|          | 3/258 [00:32<46:10, 10.86s/it, v_num=1, loss=9.870]Epoch 0:   1%|          | 3/258 [00:33<47:24, 11.16s/it, v_num=1, loss=9.380]Epoch 0:   2%|▏         | 4/258 [00:43<45:43, 10.80s/it, v_num=1, loss=9.380]Epoch 0:   2%|▏         | 4/258 [00:44<46:44, 11.04s/it, v_num=1, loss=9.200]Epoch 0:   2%|▏         | 5/258 [00:52<44:36, 10.58s/it, v_num=1, loss=9.200]Epoch 0:   2%|▏         | 5/258 [00:53<45:22, 10.76s/it, v_num=1, loss=8.830]Epoch 0:   2%|▏         | 6/258 [01:02<43:48, 10.43s/it, v_num=1, loss=8.830]Epoch 0:   2%|▏         | 6/258 [01:03<44:26, 10.58s/it, v_num=1, loss=8.710]Epoch 0:   3%|▎         | 7/258 [01:12<43:11, 10.32s/it, v_num=1, loss=8.710]Epoch 0:   3%|▎         | 7/258 [01:13<43:44, 10.46s/it, v_num=1, loss=8.210]Epoch 0:   3%|▎         | 8/258 [01:22<43:01, 10.33s/it, v_num=1, loss=8.210]Epoch 0:   3%|▎         | 8/258 [01:23<43:29, 10.44s/it, v_num=1, loss=8.380]Epoch 0:   3%|▎         | 9/258 [01:32<42:31, 10.25s/it, v_num=1, loss=8.380]Epoch 0:   3%|▎         | 9/258 [01:33<42:59, 10.36s/it, v_num=1, loss=8.440]Epoch 0:   4%|▍         | 10/258 [01:42<42:10, 10.20s/it, v_num=1, loss=8.440]Epoch 0:   4%|▍         | 10/258 [01:42<42:33, 10.29s/it, v_num=1, loss=8.140]Epoch 0:   4%|▍         | 11/258 [01:52<42:06, 10.23s/it, v_num=1, loss=8.140]Epoch 0:   4%|▍         | 11/258 [01:53<42:26, 10.31s/it, v_num=1, loss=8.020]Epoch 0:   5%|▍         | 12/258 [02:02<41:48, 10.20s/it, v_num=1, loss=8.020]Epoch 0:   5%|▍         | 12/258 [02:03<42:09, 10.28s/it, v_num=1, loss=8.030]Epoch 0:   5%|▌         | 13/258 [02:12<41:40, 10.20s/it, v_num=1, loss=8.030]Epoch 0:   5%|▌         | 13/258 [02:13<41:56, 10.27s/it, v_num=1, loss=7.640]Epoch 0:   5%|▌         | 14/258 [02:22<41:32, 10.21s/it, v_num=1, loss=7.640]Epoch 0:   5%|▌         | 14/258 [02:23<41:47, 10.28s/it, v_num=1, loss=7.830]Epoch 0:   6%|▌         | 15/258 [02:32<41:12, 10.17s/it, v_num=1, loss=7.830]Epoch 0:   6%|▌         | 15/258 [02:33<41:27, 10.23s/it, v_num=1, loss=7.410]Epoch 0:   6%|▌         | 16/258 [02:42<40:56, 10.15s/it, v_num=1, loss=7.410]Epoch 0:   6%|▌         | 16/258 [02:43<41:11, 10.21s/it, v_num=1, loss=7.530]Epoch 0:   7%|▋         | 17/258 [02:53<40:58, 10.20s/it, v_num=1, loss=7.530]Epoch 0:   7%|▋         | 17/258 [02:54<41:10, 10.25s/it, v_num=1, loss=7.500]Epoch 0:   7%|▋         | 18/258 [03:03<40:48, 10.20s/it, v_num=1, loss=7.500]Epoch 0:   7%|▋         | 18/258 [03:04<41:01, 10.26s/it, v_num=1, loss=7.450]Epoch 0:   7%|▋         | 19/258 [03:13<40:33, 10.18s/it, v_num=1, loss=7.450]Epoch 0:   7%|▋         | 19/258 [03:14<40:45, 10.23s/it, v_num=1, loss=7.430]Epoch 0:   8%|▊         | 20/258 [03:23<40:19, 10.17s/it, v_num=1, loss=7.430]Epoch 0:   8%|▊         | 20/258 [03:24<40:31, 10.21s/it, v_num=1, loss=7.390]Epoch 0:   8%|▊         | 21/258 [03:33<40:13, 10.18s/it, v_num=1, loss=7.390]Epoch 0:   8%|▊         | 21/258 [03:34<40:23, 10.23s/it, v_num=1, loss=7.190]Epoch 0:   9%|▊         | 22/258 [03:43<39:57, 10.16s/it, v_num=1, loss=7.190]Epoch 0:   9%|▊         | 22/258 [03:44<40:07, 10.20s/it, v_num=1, loss=7.370]Epoch 0:   9%|▉         | 23/258 [03:53<39:44, 10.15s/it, v_num=1, loss=7.370]Epoch 0:   9%|▉         | 23/258 [03:54<39:53, 10.19s/it, v_num=1, loss=7.170]Epoch 0:   9%|▉         | 24/258 [04:04<39:39, 10.17s/it, v_num=1, loss=7.170]Epoch 0:   9%|▉         | 24/258 [04:05<39:49, 10.21s/it, v_num=1, loss=7.390]Epoch 0:  10%|▉         | 25/258 [04:14<39:28, 10.17s/it, v_num=1, loss=7.390]Epoch 0:  10%|▉         | 25/258 [04:15<39:37, 10.20s/it, v_num=1, loss=7.220]Epoch 0:  10%|█         | 26/258 [04:23<39:14, 10.15s/it, v_num=1, loss=7.220]Epoch 0:  10%|█         | 26/258 [04:24<39:22, 10.18s/it, v_num=1, loss=7.090]Epoch 0:  10%|█         | 27/258 [04:34<39:07, 10.16s/it, v_num=1, loss=7.090]Epoch 0:  10%|█         | 27/258 [04:35<39:15, 10.20s/it, v_num=1, loss=6.820]Epoch 0:  11%|█         | 28/258 [04:43<38:52, 10.14s/it, v_num=1, loss=6.820]Epoch 0:  11%|█         | 28/258 [04:44<39:00, 10.17s/it, v_num=1, loss=7.080]Epoch 0:  11%|█         | 29/258 [04:53<38:38, 10.12s/it, v_num=1, loss=7.080]Epoch 0:  11%|█         | 29/258 [04:54<38:45, 10.15s/it, v_num=1, loss=6.960]Epoch 0:  12%|█▏        | 30/258 [05:03<38:25, 10.11s/it, v_num=1, loss=6.960]Epoch 0:  12%|█▏        | 30/258 [05:04<38:32, 10.14s/it, v_num=1, loss=7.080]Epoch 0:  12%|█▏        | 31/258 [05:14<38:21, 10.14s/it, v_num=1, loss=7.080]Epoch 0:  12%|█▏        | 31/258 [05:15<38:28, 10.17s/it, v_num=1, loss=6.870]Epoch 0:  12%|█▏        | 32/258 [05:24<38:08, 10.13s/it, v_num=1, loss=6.870]Epoch 0:  12%|█▏        | 32/258 [05:24<38:14, 10.15s/it, v_num=1, loss=6.840]Epoch 0:  13%|█▎        | 33/258 [05:33<37:57, 10.12s/it, v_num=1, loss=6.840]Epoch 0:  13%|█▎        | 33/258 [05:34<38:03, 10.15s/it, v_num=1, loss=6.560]Epoch 0:  13%|█▎        | 34/258 [05:44<37:50, 10.14s/it, v_num=1, loss=6.560]Epoch 0:  13%|█▎        | 34/258 [05:45<37:56, 10.16s/it, v_num=1, loss=7.010]Epoch 0:  14%|█▎        | 35/258 [05:54<37:36, 10.12s/it, v_num=1, loss=7.010]Epoch 0:  14%|█▎        | 35/258 [05:55<37:42, 10.15s/it, v_num=1, loss=6.810]Epoch 0:  14%|█▍        | 36/258 [06:03<37:23, 10.11s/it, v_num=1, loss=6.810]Epoch 0:  14%|█▍        | 36/258 [06:04<37:29, 10.13s/it, v_num=1, loss=6.760]Epoch 0:  14%|█▍        | 37/258 [06:14<37:17, 10.12s/it, v_num=1, loss=6.760]Epoch 0:  14%|█▍        | 37/258 [06:15<37:22, 10.15s/it, v_num=1, loss=6.600]Epoch 0:  15%|█▍        | 38/258 [06:24<37:03, 10.11s/it, v_num=1, loss=6.600]Epoch 0:  15%|█▍        | 38/258 [06:25<37:09, 10.13s/it, v_num=1, loss=6.870]Epoch 0:  15%|█▌        | 39/258 [06:33<36:50, 10.09s/it, v_num=1, loss=6.870]Epoch 0:  15%|█▌        | 39/258 [06:34<36:55, 10.12s/it, v_num=1, loss=6.200]Epoch 0:  16%|█▌        | 40/258 [06:43<36:37, 10.08s/it, v_num=1, loss=6.200]Epoch 0:  16%|█▌        | 40/258 [06:44<36:46, 10.12s/it, v_num=1, loss=6.280]Epoch 0:  16%|█▌        | 41/258 [06:53<36:29, 10.09s/it, v_num=1, loss=6.280]Epoch 0:  16%|█▌        | 41/258 [06:54<36:33, 10.11s/it, v_num=1, loss=6.550]Epoch 0:  16%|█▋        | 42/258 [07:03<36:17, 10.08s/it, v_num=1, loss=6.550]Epoch 0:  16%|█▋        | 42/258 [07:04<36:21, 10.10s/it, v_num=1, loss=6.610]Epoch 0:  17%|█▋        | 43/258 [07:12<36:04, 10.07s/it, v_num=1, loss=6.610]Epoch 0:  17%|█▋        | 43/258 [07:13<36:09, 10.09s/it, v_num=1, loss=6.520]Epoch 0:  17%|█▋        | 44/258 [07:23<35:57, 10.08s/it, v_num=1, loss=6.520]Epoch 0:  17%|█▋        | 44/258 [07:24<36:01, 10.10s/it, v_num=1, loss=6.900]Epoch 0:  17%|█▋        | 45/258 [07:33<35:44, 10.07s/it, v_num=1, loss=6.900]Epoch 0:  17%|█▋        | 45/258 [07:33<35:48, 10.09s/it, v_num=1, loss=6.330]Epoch 0:  18%|█▊        | 46/258 [07:42<35:32, 10.06s/it, v_num=1, loss=6.330]Epoch 0:  18%|█▊        | 46/258 [07:43<35:36, 10.08s/it, v_num=1, loss=6.160]Epoch 0:  18%|█▊        | 47/258 [07:53<35:24, 10.07s/it, v_num=1, loss=6.160]Epoch 0:  18%|█▊        | 47/258 [07:54<35:28, 10.09s/it, v_num=1, loss=5.910]Epoch 0:  19%|█▊        | 48/258 [08:02<35:11, 10.06s/it, v_num=1, loss=5.910]Epoch 0:  19%|█▊        | 48/258 [08:03<35:15, 10.08s/it, v_num=1, loss=6.480]Epoch 0:  19%|█▉        | 49/258 [08:13<35:04, 10.07s/it, v_num=1, loss=6.480]Epoch 0:  19%|█▉        | 49/258 [08:14<35:08, 10.09s/it, v_num=1, loss=6.400]Epoch 0:  19%|█▉        | 50/258 [08:22<34:52, 10.06s/it, v_num=1, loss=6.400]Epoch 0:  19%|█▉        | 50/258 [08:24<34:59, 10.09s/it, v_num=1, loss=5.890]Epoch 0:  20%|█▉        | 51/258 [08:33<34:43, 10.07s/it, v_num=1, loss=5.890]Epoch 0:  20%|█▉        | 51/258 [08:34<34:47, 10.08s/it, v_num=1, loss=5.980]Epoch 0:  20%|██        | 52/258 [08:42<34:31, 10.06s/it, v_num=1, loss=5.980]Epoch 0:  20%|██        | 52/258 [08:43<34:34, 10.07s/it, v_num=1, loss=6.010]Epoch 0:  21%|██        | 53/258 [08:52<34:19, 10.05s/it, v_num=1, loss=6.010]Epoch 0:  21%|██        | 53/258 [08:53<34:22, 10.06s/it, v_num=1, loss=6.010]Epoch 0:  21%|██        | 54/258 [09:03<34:11, 10.06s/it, v_num=1, loss=6.010]Epoch 0:  21%|██        | 54/258 [09:04<34:15, 10.08s/it, v_num=1, loss=6.040]Epoch 0:  21%|██▏       | 55/258 [09:13<34:02, 10.06s/it, v_num=1, loss=6.040]Epoch 0:  21%|██▏       | 55/258 [09:14<34:05, 10.08s/it, v_num=1, loss=6.220]Epoch 0:  22%|██▏       | 56/258 [09:22<33:50, 10.05s/it, v_num=1, loss=6.220]Epoch 0:  22%|██▏       | 56/258 [09:23<33:54, 10.07s/it, v_num=1, loss=6.180]Epoch 0:  22%|██▏       | 57/258 [09:33<33:42, 10.06s/it, v_num=1, loss=6.180]Epoch 0:  22%|██▏       | 57/258 [09:34<33:45, 10.08s/it, v_num=1, loss=6.070]Epoch 0:  22%|██▏       | 58/258 [09:43<33:32, 10.06s/it, v_num=1, loss=6.070]Epoch 0:  22%|██▏       | 58/258 [09:44<33:35, 10.08s/it, v_num=1, loss=6.040]Epoch 0:  23%|██▎       | 59/258 [09:53<33:20, 10.05s/it, v_num=1, loss=6.040]Epoch 0:  23%|██▎       | 59/258 [09:54<33:23, 10.07s/it, v_num=1, loss=6.070]Epoch 0:  23%|██▎       | 60/258 [10:04<33:14, 10.07s/it, v_num=1, loss=6.070]Epoch 0:  23%|██▎       | 60/258 [10:05<33:17, 10.09s/it, v_num=1, loss=5.610]Epoch 0:  24%|██▎       | 61/258 [10:14<33:05, 10.08s/it, v_num=1, loss=5.610]Epoch 0:  24%|██▎       | 61/258 [10:15<33:09, 10.10s/it, v_num=1, loss=5.780]Epoch 0:  24%|██▍       | 62/258 [10:25<32:58, 10.09s/it, v_num=1, loss=5.780]Epoch 0:  24%|██▍       | 62/258 [10:26<33:01, 10.11s/it, v_num=1, loss=5.900]Epoch 0:  24%|██▍       | 63/258 [10:36<32:50, 10.11s/it, v_num=1, loss=5.900]Epoch 0:  24%|██▍       | 63/258 [10:37<32:53, 10.12s/it, v_num=1, loss=5.820]Epoch 0:  25%|██▍       | 64/258 [10:46<32:40, 10.11s/it, v_num=1, loss=5.820]Epoch 0:  25%|██▍       | 64/258 [10:47<32:43, 10.12s/it, v_num=1, loss=6.030]Epoch 0:  25%|██▌       | 65/258 [10:56<32:29, 10.10s/it, v_num=1, loss=6.030]Epoch 0:  25%|██▌       | 65/258 [10:57<32:32, 10.12s/it, v_num=1, loss=5.880]Epoch 0:  26%|██▌       | 66/258 [11:06<32:20, 10.11s/it, v_num=1, loss=5.880]Epoch 0:  26%|██▌       | 66/258 [11:07<32:23, 10.12s/it, v_num=1, loss=5.680]Epoch 0:  26%|██▌       | 67/258 [11:18<32:14, 10.13s/it, v_num=1, loss=5.680]Epoch 0:  26%|██▌       | 67/258 [11:19<32:16, 10.14s/it, v_num=1, loss=6.270]Epoch 0:  26%|██▋       | 68/258 [11:28<32:02, 10.12s/it, v_num=1, loss=6.270]Epoch 0:  26%|██▋       | 68/258 [11:29<32:05, 10.13s/it, v_num=1, loss=5.550]Epoch 0:  27%|██▋       | 69/258 [11:37<31:51, 10.12s/it, v_num=1, loss=5.550]Epoch 0:  27%|██▋       | 69/258 [11:38<31:54, 10.13s/it, v_num=1, loss=5.990]Epoch 0:  27%|██▋       | 70/258 [11:48<31:43, 10.12s/it, v_num=1, loss=5.990]Epoch 0:  27%|██▋       | 70/258 [11:49<31:45, 10.14s/it, v_num=1, loss=5.580]Epoch 0:  28%|██▊       | 71/258 [12:00<31:37, 10.15s/it, v_num=1, loss=5.580]Epoch 0:  28%|██▊       | 71/258 [12:02<31:42, 10.17s/it, v_num=1, loss=5.590]Epoch 0:  28%|██▊       | 72/258 [12:17<31:46, 10.25s/it, v_num=1, loss=5.590]Epoch 0:  28%|██▊       | 72/258 [12:18<31:48, 10.26s/it, v_num=1, loss=6.180]Epoch 0:  28%|██▊       | 73/258 [12:30<31:40, 10.27s/it, v_num=1, loss=6.180]Epoch 0:  28%|██▊       | 73/258 [12:31<31:43, 10.29s/it, v_num=1, loss=5.940]Epoch 0:  29%|██▊       | 74/258 [12:41<31:33, 10.29s/it, v_num=1, loss=5.940]Epoch 0:  29%|██▊       | 74/258 [12:42<31:36, 10.31s/it, v_num=1, loss=5.820]Epoch 0:  29%|██▉       | 75/258 [12:53<31:27, 10.32s/it, v_num=1, loss=5.820]Epoch 0:  29%|██▉       | 75/258 [12:54<31:30, 10.33s/it, v_num=1, loss=5.720]Epoch 0:  29%|██▉       | 76/258 [13:04<31:18, 10.32s/it, v_num=1, loss=5.720]Epoch 0:  29%|██▉       | 76/258 [13:05<31:20, 10.33s/it, v_num=1, loss=5.630]Epoch 0:  30%|██▉       | 77/258 [13:14<31:06, 10.31s/it, v_num=1, loss=5.630]Epoch 0:  30%|██▉       | 77/258 [13:15<31:09, 10.33s/it, v_num=1, loss=5.880]Epoch 0:  30%|███       | 78/258 [13:25<30:58, 10.32s/it, v_num=1, loss=5.880]Epoch 0:  30%|███       | 78/258 [13:26<31:00, 10.34s/it, v_num=1, loss=5.540]Epoch 0:  31%|███       | 79/258 [13:35<30:47, 10.32s/it, v_num=1, loss=5.540]Epoch 0:  31%|███       | 79/258 [13:36<30:49, 10.33s/it, v_num=1, loss=5.720]Epoch 0:  31%|███       | 80/258 [13:45<30:36, 10.32s/it, v_num=1, loss=5.720]Epoch 0:  31%|███       | 80/258 [13:46<30:38, 10.33s/it, v_num=1, loss=5.220]Epoch 0:  31%|███▏      | 81/258 [13:56<30:27, 10.32s/it, v_num=1, loss=5.220]Epoch 0:  31%|███▏      | 81/258 [13:57<30:29, 10.33s/it, v_num=1, loss=6.180]Epoch 0:  32%|███▏      | 82/258 [14:06<30:16, 10.32s/it, v_num=1, loss=6.180]Epoch 0:  32%|███▏      | 82/258 [14:07<30:18, 10.33s/it, v_num=1, loss=5.180]Epoch 0:  32%|███▏      | 83/258 [14:16<30:05, 10.32s/it, v_num=1, loss=5.180]Epoch 0:  32%|███▏      | 83/258 [14:17<30:07, 10.33s/it, v_num=1, loss=6.180]Epoch 0:  33%|███▎      | 84/258 [14:26<29:53, 10.31s/it, v_num=1, loss=6.180]Epoch 0:  33%|███▎      | 84/258 [14:26<29:55, 10.32s/it, v_num=1, loss=5.270]Epoch 0:  33%|███▎      | 85/258 [14:36<29:44, 10.31s/it, v_num=1, loss=5.270]Epoch 0:  33%|███▎      | 85/258 [14:37<29:46, 10.32s/it, v_num=1, loss=5.740]Epoch 0:  33%|███▎      | 86/258 [14:45<29:31, 10.30s/it, v_num=1, loss=5.740]Epoch 0:  33%|███▎      | 86/258 [14:46<29:33, 10.31s/it, v_num=1, loss=5.380]Epoch 0:  34%|███▎      | 87/258 [14:55<29:20, 10.30s/it, v_num=1, loss=5.380]Epoch 0:  34%|███▎      | 87/258 [14:56<29:22, 10.31s/it, v_num=1, loss=5.810]Epoch 0:  34%|███▍      | 88/258 [15:06<29:12, 10.31s/it, v_num=1, loss=5.810]Epoch 0:  34%|███▍      | 88/258 [15:07<29:13, 10.32s/it, v_num=1, loss=5.630]Epoch 0:  34%|███▍      | 89/258 [15:16<29:00, 10.30s/it, v_num=1, loss=5.630]Epoch 0:  34%|███▍      | 89/258 [15:17<29:02, 10.31s/it, v_num=1, loss=4.880]Epoch 0:  35%|███▍      | 90/258 [15:26<28:49, 10.30s/it, v_num=1, loss=4.880]Epoch 0:  35%|███▍      | 90/258 [15:27<28:51, 10.31s/it, v_num=1, loss=5.790]Epoch 0:  35%|███▌      | 91/258 [15:37<28:41, 10.31s/it, v_num=1, loss=5.790]Epoch 0:  35%|███▌      | 91/258 [15:38<28:42, 10.32s/it, v_num=1, loss=5.900]Epoch 0:  36%|███▌      | 92/258 [15:47<28:29, 10.30s/it, v_num=1, loss=5.900]Epoch 0:  36%|███▌      | 92/258 [15:48<28:31, 10.31s/it, v_num=1, loss=5.900]Epoch 0:  36%|███▌      | 93/258 [15:57<28:19, 10.30s/it, v_num=1, loss=5.900]Epoch 0:  36%|███▌      | 93/258 [15:58<28:21, 10.31s/it, v_num=1, loss=5.690]Epoch 0:  36%|███▋      | 94/258 [16:09<28:12, 10.32s/it, v_num=1, loss=5.690]Epoch 0:  36%|███▋      | 94/258 [16:10<28:13, 10.33s/it, v_num=1, loss=5.630]Epoch 0:  37%|███▋      | 95/258 [16:20<28:02, 10.32s/it, v_num=1, loss=5.630]Epoch 0:  37%|███▋      | 95/258 [16:21<28:04, 10.33s/it, v_num=1, loss=5.670]Epoch 0:  37%|███▋      | 96/258 [16:30<27:51, 10.32s/it, v_num=1, loss=5.670]Epoch 0:  37%|███▋      | 96/258 [16:31<27:52, 10.33s/it, v_num=1, loss=5.440]Epoch 0:  38%|███▊      | 97/258 [16:40<27:39, 10.31s/it, v_num=1, loss=5.440]Epoch 0:  38%|███▊      | 97/258 [16:42<27:43, 10.33s/it, v_num=1, loss=5.990]Epoch 0:  38%|███▊      | 98/258 [16:50<27:30, 10.32s/it, v_num=1, loss=5.990]Epoch 0:  38%|███▊      | 98/258 [16:51<27:31, 10.32s/it, v_num=1, loss=5.580]Epoch 0:  38%|███▊      | 99/258 [17:00<27:19, 10.31s/it, v_num=1, loss=5.580]Epoch 0:  38%|███▊      | 99/258 [17:01<27:20, 10.32s/it, v_num=1, loss=5.410]Epoch 0:  39%|███▉      | 100/258 [17:10<27:08, 10.30s/it, v_num=1, loss=5.410]Epoch 0:  39%|███▉      | 100/258 [17:11<27:09, 10.31s/it, v_num=1, loss=5.730]Epoch 0:  39%|███▉      | 101/258 [17:21<26:59, 10.31s/it, v_num=1, loss=5.730]Epoch 0:  39%|███▉      | 101/258 [17:22<27:00, 10.32s/it, v_num=1, loss=5.330]Epoch 0:  40%|███▉      | 102/258 [17:31<26:47, 10.31s/it, v_num=1, loss=5.330]Epoch 0:  40%|███▉      | 102/258 [17:32<26:49, 10.32s/it, v_num=1, loss=5.470]{'accelerator': 'gpu',
 'accumulate_grad_batches': 1,
 'annotation': 'data/iu_xray/annotation.json',
 'base_dir': './data/iu_xray/images',
 'batch_size': 8,
 'beam_size': 3,
 'ckpt_file': None,
 'dataset': 'iu_xray',
 'delta_file': None,
 'devices': 1,
 'diversity_penalty': 0,
 'do_sample': False,
 'end_sym': '</s>',
 'every_n_train_steps': 0,
 'freeze_vm': True,
 'global_only': False,
 'gradient_clip_val': None,
 'learning_rate': 0.0001,
 'length_penalty': 2.0,
 'limit_test_batches': 1.0,
 'limit_train_batches': 1.0,
 'limit_val_batches': 1.0,
 'llama_model': 'TinyLlama/TinyLlama-1.1B-Chat-v1.0',
 'llm_alpha': 16,
 'llm_r': 16,
 'llm_use_lora': False,
 'lora_dropout': 0.1,
 'low_resource': False,
 'max_epochs': 15,
 'max_length': 60,
 'max_new_tokens': 100,
 'min_new_tokens': 40,
 'no_repeat_ngram_size': 2,
 'num_beam_groups': 1,
 'num_nodes': 1,
 'num_sanity_val_steps': 0,
 'num_workers': 8,
 'precision': 'bf16-mixed',
 'prefetch_factor': 4,
 'repetition_penalty': 2.0,
 'savedmodel_path': './save/iu_xray/v1_shallow',
 'scorer_types': ['Bleu_4', 'CIDEr'],
 'strategy': 'auto',
 'temperature': 0,
 'test': False,
 'test_batch_size': 16,
 'val_batch_size': 12,
 'val_check_interval': 1.0,
 'validate': False,
 'vis_alpha': 16,
 'vis_r': 16,
 'vis_use_lora': False,
 'vision_model': 'microsoft/swin-base-patch4-window7-224',
 'weights': [0.5, 0.5]}
Global seed set to 42
Using bfloat16 Automatic Mixed Precision (AMP)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
Loading vision encoder:microsoft/swin-base-patch4-window7-224
/home/sandy/miniconda3/envs/success/lib/python3.9/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Some weights of the model checkpoint at microsoft/swin-base-patch4-window7-224 were not used when initializing SwinModel: ['classifier.weight', 'classifier.bias']
- This IS expected if you are initializing SwinModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing SwinModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Loading Frozen vision encoder:microsoft/swin-base-patch4-window7-224 -- Done
Loading LLAMA
Some weights of LlamaForCausalLM were not initialized from the model checkpoint at TinyLlama/TinyLlama-1.1B-Chat-v1.0 and are newly initialized: ['model.layers.13.self_attn.rotary_emb.inv_freq', 'model.layers.0.self_attn.rotary_emb.inv_freq', 'model.layers.16.self_attn.rotary_emb.inv_freq', 'model.layers.2.self_attn.rotary_emb.inv_freq', 'model.layers.6.self_attn.rotary_emb.inv_freq', 'model.layers.19.self_attn.rotary_emb.inv_freq', 'model.layers.1.self_attn.rotary_emb.inv_freq', 'model.layers.10.self_attn.rotary_emb.inv_freq', 'model.layers.17.self_attn.rotary_emb.inv_freq', 'model.layers.9.self_attn.rotary_emb.inv_freq', 'model.layers.5.self_attn.rotary_emb.inv_freq', 'model.layers.8.self_attn.rotary_emb.inv_freq', 'model.layers.11.self_attn.rotary_emb.inv_freq', 'model.layers.18.self_attn.rotary_emb.inv_freq', 'model.layers.7.self_attn.rotary_emb.inv_freq', 'model.layers.3.self_attn.rotary_emb.inv_freq', 'model.layers.15.self_attn.rotary_emb.inv_freq', 'model.layers.12.self_attn.rotary_emb.inv_freq', 'model.layers.4.self_attn.rotary_emb.inv_freq', 'model.layers.20.self_attn.rotary_emb.inv_freq', 'model.layers.21.self_attn.rotary_emb.inv_freq', 'model.layers.14.self_attn.rotary_emb.inv_freq']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of LlamaForCausalLM were not initialized from the model checkpoint at TinyLlama/TinyLlama-1.1B-Chat-v1.0 and are newly initialized because the shapes did not match:
- model.layers.0.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.0.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.1.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.1.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.10.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.10.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.11.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.11.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.12.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.12.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.13.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.13.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.14.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.14.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.15.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.15.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.16.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.16.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.17.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.17.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.18.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.18.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.19.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.19.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.2.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.2.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.20.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.20.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.21.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.21.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.3.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.3.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.4.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.4.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.5.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.5.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.6.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.6.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.7.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.7.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.8.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.8.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.9.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.9.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Loading LLAMA Done
You are using a CUDA device ('NVIDIA GeForce RTX 3060 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.
Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.
Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name           | Type             | Params
----------------------------------------------------
0 | visual_encoder | SwinModel        | 86.7 M
1 | llama_model    | LlamaForCausalLM | 1.3 B 
2 | embed_tokens   | Embedding        | 65.5 M
3 | llama_proj     | Linear           | 2.1 M 
4 | layer_norm     | LayerNorm        | 4.1 K 
----------------------------------------------------
2.1 M     Trainable params
1.3 B     Non-trainable params
1.4 B     Total params
5,401.502 Total estimated model params size (MB)
Training: 0it [00:00, ?it/s]Training:   0%|          | 0/258 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/258 [00:00<?, ?it/s] Epoch 0:   0%|          | 1/258 [00:13<59:50, 13.97s/it]Epoch 0:   0%|          | 1/258 [00:13<59:50, 13.97s/it, v_num=2, loss=10.60]Epoch 0:   1%|          | 2/258 [00:22<47:21, 11.10s/it, v_num=2, loss=10.60]Epoch 0:   1%|          | 2/258 [00:23<49:08, 11.52s/it, v_num=2, loss=9.870]Epoch 0:   1%|          | 3/258 [00:31<45:02, 10.60s/it, v_num=2, loss=9.870]Epoch 0:   1%|          | 3/258 [00:32<46:20, 10.91s/it, v_num=2, loss=9.380]{'accelerator': 'gpu',
 'accumulate_grad_batches': 1,
 'annotation': 'data/iu_xray/annotation.json',
 'base_dir': './data/iu_xray/images',
 'batch_size': 8,
 'beam_size': 3,
 'ckpt_file': None,
 'dataset': 'iu_xray',
 'delta_file': None,
 'devices': 1,
 'diversity_penalty': 0,
 'do_sample': False,
 'end_sym': '</s>',
 'every_n_train_steps': 0,
 'freeze_vm': True,
 'global_only': False,
 'gradient_clip_val': None,
 'learning_rate': 0.0001,
 'length_penalty': 2.0,
 'limit_test_batches': 1.0,
 'limit_train_batches': 1.0,
 'limit_val_batches': 1.0,
 'llama_model': 'TinyLlama/TinyLlama-1.1B-Chat-v1.0',
 'llm_alpha': 16,
 'llm_r': 16,
 'llm_use_lora': False,
 'lora_dropout': 0.1,
 'low_resource': False,
 'max_epochs': 15,
 'max_length': 60,
 'max_new_tokens': 100,
 'min_new_tokens': 40,
 'no_repeat_ngram_size': 2,
 'num_beam_groups': 1,
 'num_nodes': 1,
 'num_sanity_val_steps': 0,
 'num_workers': 8,
 'precision': 'bf16-mixed',
 'prefetch_factor': 4,
 'repetition_penalty': 2.0,
 'savedmodel_path': './save/iu_xray/v1_shallow',
 'scorer_types': ['Bleu_4', 'CIDEr'],
 'strategy': 'auto',
 'temperature': 0,
 'test': False,
 'test_batch_size': 16,
 'val_batch_size': 12,
 'val_check_interval': 1.0,
 'validate': False,
 'vis_alpha': 16,
 'vis_r': 16,
 'vis_use_lora': False,
 'vision_model': 'microsoft/swin-base-patch4-window7-224',
 'weights': [0.5, 0.5]}
Global seed set to 42
Using bfloat16 Automatic Mixed Precision (AMP)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
Loading vision encoder:microsoft/swin-base-patch4-window7-224
/home/sandy/miniconda3/envs/success/lib/python3.9/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Some weights of the model checkpoint at microsoft/swin-base-patch4-window7-224 were not used when initializing SwinModel: ['classifier.weight', 'classifier.bias']
- This IS expected if you are initializing SwinModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing SwinModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Loading Frozen vision encoder:microsoft/swin-base-patch4-window7-224 -- Done
Loading LLAMA
Some weights of LlamaForCausalLM were not initialized from the model checkpoint at TinyLlama/TinyLlama-1.1B-Chat-v1.0 and are newly initialized: ['model.layers.16.self_attn.rotary_emb.inv_freq', 'model.layers.6.self_attn.rotary_emb.inv_freq', 'model.layers.4.self_attn.rotary_emb.inv_freq', 'model.layers.20.self_attn.rotary_emb.inv_freq', 'model.layers.19.self_attn.rotary_emb.inv_freq', 'model.layers.2.self_attn.rotary_emb.inv_freq', 'model.layers.21.self_attn.rotary_emb.inv_freq', 'model.layers.7.self_attn.rotary_emb.inv_freq', 'model.layers.17.self_attn.rotary_emb.inv_freq', 'model.layers.0.self_attn.rotary_emb.inv_freq', 'model.layers.15.self_attn.rotary_emb.inv_freq', 'model.layers.14.self_attn.rotary_emb.inv_freq', 'model.layers.5.self_attn.rotary_emb.inv_freq', 'model.layers.12.self_attn.rotary_emb.inv_freq', 'model.layers.11.self_attn.rotary_emb.inv_freq', 'model.layers.13.self_attn.rotary_emb.inv_freq', 'model.layers.10.self_attn.rotary_emb.inv_freq', 'model.layers.1.self_attn.rotary_emb.inv_freq', 'model.layers.18.self_attn.rotary_emb.inv_freq', 'model.layers.9.self_attn.rotary_emb.inv_freq', 'model.layers.8.self_attn.rotary_emb.inv_freq', 'model.layers.3.self_attn.rotary_emb.inv_freq']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of LlamaForCausalLM were not initialized from the model checkpoint at TinyLlama/TinyLlama-1.1B-Chat-v1.0 and are newly initialized because the shapes did not match:
- model.layers.0.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.0.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.1.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.1.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.10.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.10.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.11.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.11.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.12.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.12.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.13.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.13.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.14.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.14.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.15.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.15.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.16.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.16.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.17.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.17.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.18.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.18.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.19.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.19.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.2.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.2.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.20.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.20.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.21.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.21.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.3.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.3.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.4.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.4.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.5.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.5.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.6.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.6.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.7.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.7.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.8.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.8.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.9.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.9.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Loading LLAMA Done
You are using a CUDA device ('NVIDIA GeForce RTX 3060 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.
Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.
Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.
  Dataset sizes:
  Train:      2069 samples
  Validation: 296 samples
  Test:       590 samples
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name           | Type             | Params
----------------------------------------------------
0 | visual_encoder | SwinModel        | 86.7 M
1 | llama_model    | LlamaForCausalLM | 1.3 B 
2 | embed_tokens   | Embedding        | 65.5 M
3 | llama_proj     | Linear           | 2.1 M 
4 | layer_norm     | LayerNorm        | 4.1 K 
----------------------------------------------------
2.1 M     Trainable params
1.3 B     Non-trainable params
1.4 B     Total params
5,401.502 Total estimated model params size (MB)
Training: 0it [00:00, ?it/s]Training:   0%|          | 0/258 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/258 [00:00<?, ?it/s] Epoch 0:   0%|          | 1/258 [00:14<1:01:08, 14.27s/it]Epoch 0:   0%|          | 1/258 [00:14<1:01:08, 14.28s/it, v_num=3, loss=10.60]Epoch 0:   1%|          | 2/258 [00:22<48:20, 11.33s/it, v_num=3, loss=10.60]  Epoch 0:   1%|          | 2/258 [00:23<50:05, 11.74s/it, v_num=3, loss=9.870]Epoch 0:   1%|          | 3/258 [00:31<45:17, 10.66s/it, v_num=3, loss=9.870]Epoch 0:   1%|          | 3/258 [00:32<46:33, 10.95s/it, v_num=3, loss=9.380]{'accelerator': 'gpu',
 'accumulate_grad_batches': 1,
 'annotation': 'data/iu_xray/annotation.json',
 'base_dir': './data/iu_xray/images',
 'batch_size': 8,
 'beam_size': 3,
 'ckpt_file': None,
 'dataset': 'iu_xray',
 'delta_file': None,
 'devices': 1,
 'diversity_penalty': 0,
 'do_sample': False,
 'end_sym': '</s>',
 'every_n_train_steps': 0,
 'freeze_vm': True,
 'global_only': False,
 'gradient_clip_val': None,
 'learning_rate': 0.0001,
 'length_penalty': 2.0,
 'limit_test_batches': 1.0,
 'limit_train_batches': 1.0,
 'limit_val_batches': 1.0,
 'llama_model': 'TinyLlama/TinyLlama-1.1B-Chat-v1.0',
 'llm_alpha': 16,
 'llm_r': 16,
 'llm_use_lora': False,
 'lora_dropout': 0.1,
 'low_resource': False,
 'max_epochs': 15,
 'max_length': 60,
 'max_new_tokens': 100,
 'min_new_tokens': 40,
 'no_repeat_ngram_size': 2,
 'num_beam_groups': 1,
 'num_nodes': 1,
 'num_sanity_val_steps': 0,
 'num_workers': 8,
 'precision': 'bf16-mixed',
 'prefetch_factor': 4,
 'repetition_penalty': 2.0,
 'savedmodel_path': './save/iu_xray/v1_shallow',
 'scorer_types': ['Bleu_4', 'CIDEr'],
 'strategy': 'auto',
 'temperature': 0,
 'test': False,
 'test_batch_size': 16,
 'val_batch_size': 12,
 'val_check_interval': 1.0,
 'validate': False,
 'vis_alpha': 16,
 'vis_r': 16,
 'vis_use_lora': False,
 'vision_model': 'microsoft/swin-base-patch4-window7-224',
 'weights': [0.5, 0.5]}
Global seed set to 42
Using bfloat16 Automatic Mixed Precision (AMP)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
Loading vision encoder:microsoft/swin-base-patch4-window7-224
/home/sandy/miniconda3/envs/success/lib/python3.9/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Some weights of the model checkpoint at microsoft/swin-base-patch4-window7-224 were not used when initializing SwinModel: ['classifier.bias', 'classifier.weight']
- This IS expected if you are initializing SwinModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing SwinModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Loading Frozen vision encoder:microsoft/swin-base-patch4-window7-224 -- Done
Loading LLAMA
Some weights of LlamaForCausalLM were not initialized from the model checkpoint at TinyLlama/TinyLlama-1.1B-Chat-v1.0 and are newly initialized: ['model.layers.16.self_attn.rotary_emb.inv_freq', 'model.layers.20.self_attn.rotary_emb.inv_freq', 'model.layers.15.self_attn.rotary_emb.inv_freq', 'model.layers.0.self_attn.rotary_emb.inv_freq', 'model.layers.9.self_attn.rotary_emb.inv_freq', 'model.layers.18.self_attn.rotary_emb.inv_freq', 'model.layers.5.self_attn.rotary_emb.inv_freq', 'model.layers.8.self_attn.rotary_emb.inv_freq', 'model.layers.13.self_attn.rotary_emb.inv_freq', 'model.layers.4.self_attn.rotary_emb.inv_freq', 'model.layers.21.self_attn.rotary_emb.inv_freq', 'model.layers.17.self_attn.rotary_emb.inv_freq', 'model.layers.11.self_attn.rotary_emb.inv_freq', 'model.layers.6.self_attn.rotary_emb.inv_freq', 'model.layers.12.self_attn.rotary_emb.inv_freq', 'model.layers.3.self_attn.rotary_emb.inv_freq', 'model.layers.2.self_attn.rotary_emb.inv_freq', 'model.layers.7.self_attn.rotary_emb.inv_freq', 'model.layers.14.self_attn.rotary_emb.inv_freq', 'model.layers.1.self_attn.rotary_emb.inv_freq', 'model.layers.10.self_attn.rotary_emb.inv_freq', 'model.layers.19.self_attn.rotary_emb.inv_freq']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of LlamaForCausalLM were not initialized from the model checkpoint at TinyLlama/TinyLlama-1.1B-Chat-v1.0 and are newly initialized because the shapes did not match:
- model.layers.0.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.0.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.1.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.1.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.10.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.10.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.11.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.11.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.12.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.12.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.13.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.13.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.14.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.14.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.15.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.15.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.16.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.16.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.17.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.17.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.18.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.18.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.19.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.19.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.2.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.2.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.20.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.20.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.21.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.21.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.3.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.3.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.4.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.4.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.5.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.5.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.6.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.6.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.7.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.7.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.8.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.8.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.9.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.9.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Loading LLAMA Done
You are using a CUDA device ('NVIDIA GeForce RTX 3060 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.
Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.
Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.
  Dataset sizes:
  Train:      2069 samples
  Validation: 296 samples
  Test:       590 samples
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name           | Type             | Params
----------------------------------------------------
0 | visual_encoder | SwinModel        | 86.7 M
1 | llama_model    | LlamaForCausalLM | 1.3 B 
2 | embed_tokens   | Embedding        | 65.5 M
3 | llama_proj     | Linear           | 2.1 M 
4 | layer_norm     | LayerNorm        | 4.1 K 
----------------------------------------------------
2.1 M     Trainable params
1.3 B     Non-trainable params
1.4 B     Total params
5,401.502 Total estimated model params size (MB)
Training: 0it [00:00, ?it/s]Training:   0%|          | 0/258 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/258 [00:00<?, ?it/s] Epoch 0:   0%|          | 1/258 [00:14<1:00:17, 14.08s/it]Epoch 0:   0%|          | 1/258 [00:14<1:00:17, 14.08s/it, v_num=4, loss=10.60]Epoch 0:   1%|          | 2/258 [00:23<49:56, 11.70s/it, v_num=4, loss=10.60]  Epoch 0:   1%|          | 2/258 [00:24<51:51, 12.15s/it, v_num=4, loss=9.870]Epoch 0:   1%|          | 3/258 [00:33<47:56, 11.28s/it, v_num=4, loss=9.870]Epoch 0:   1%|          | 3/258 [00:34<49:17, 11.60s/it, v_num=4, loss=9.380]Epoch 0:   2%|▏         | 4/258 [00:44<47:03, 11.12s/it, v_num=4, loss=9.380]Epoch 0:   2%|▏         | 4/258 [00:45<48:05, 11.36s/it, v_num=4, loss=9.200]Epoch 0:   2%|▏         | 5/258 [00:55<46:44, 11.08s/it, v_num=4, loss=9.200]Epoch 0:   2%|▏         | 5/258 [00:56<47:32, 11.28s/it, v_num=4, loss=8.830]Epoch 0:   2%|▏         | 6/258 [01:05<45:58, 10.95s/it, v_num=4, loss=8.830]Epoch 0:   2%|▏         | 6/258 [01:06<46:38, 11.11s/it, v_num=4, loss=8.710]Epoch 0:   3%|▎         | 7/258 [01:16<45:31, 10.88s/it, v_num=4, loss=8.710]Epoch 0:   3%|▎         | 7/258 [01:17<46:05, 11.02s/it, v_num=4, loss=8.210]Epoch 0:   3%|▎         | 8/258 [01:26<45:06, 10.82s/it, v_num=4, loss=8.210]Epoch 0:   3%|▎         | 8/258 [01:27<45:36, 10.94s/it, v_num=4, loss=8.380]Epoch 0:   3%|▎         | 9/258 [01:37<44:44, 10.78s/it, v_num=4, loss=8.380]Epoch 0:   3%|▎         | 9/258 [01:38<45:13, 10.90s/it, v_num=4, loss=8.440]Epoch 0:   4%|▍         | 10/258 [01:47<44:29, 10.76s/it, v_num=4, loss=8.440]Epoch 0:   4%|▍         | 10/258 [01:48<44:53, 10.86s/it, v_num=4, loss=8.140]Epoch 0:   4%|▍         | 11/258 [02:02<45:47, 11.13s/it, v_num=4, loss=8.140]Epoch 0:   4%|▍         | 11/258 [02:03<46:17, 11.24s/it, v_num=4, loss=8.020]Epoch 0:   5%|▍         | 12/258 [02:15<46:13, 11.27s/it, v_num=4, loss=8.020]Epoch 0:   5%|▍         | 12/258 [02:16<46:39, 11.38s/it, v_num=4, loss=8.030]Epoch 0:   5%|▌         | 13/258 [02:26<46:09, 11.30s/it, v_num=4, loss=8.030]Epoch 0:   5%|▌         | 13/258 [02:27<46:28, 11.38s/it, v_num=4, loss=7.640]Epoch 0:   5%|▌         | 14/258 [02:37<45:50, 11.27s/it, v_num=4, loss=7.640]Epoch 0:   5%|▌         | 14/258 [02:38<46:08, 11.35s/it, v_num=4, loss=7.830]Epoch 0:   6%|▌         | 15/258 [02:48<45:35, 11.26s/it, v_num=4, loss=7.830]Epoch 0:   6%|▌         | 15/258 [02:49<45:52, 11.33s/it, v_num=4, loss=7.410]Epoch 0:   6%|▌         | 16/258 [02:59<45:22, 11.25s/it, v_num=4, loss=7.410]Epoch 0:   6%|▌         | 16/258 [03:00<45:37, 11.31s/it, v_num=4, loss=7.530]Epoch 0:   7%|▋         | 17/258 [03:10<45:00, 11.21s/it, v_num=4, loss=7.530]Epoch 0:   7%|▋         | 17/258 [03:11<45:14, 11.26s/it, v_num=4, loss=7.500]Epoch 0:   7%|▋         | 18/258 [03:21<44:45, 11.19s/it, v_num=4, loss=7.500]Epoch 0:   7%|▋         | 18/258 [03:22<45:05, 11.27s/it, v_num=4, loss=7.450]Epoch 0:   7%|▋         | 19/258 [03:34<45:03, 11.31s/it, v_num=4, loss=7.450]Epoch 0:   7%|▋         | 19/258 [03:35<45:16, 11.36s/it, v_num=4, loss=7.430]Epoch 0:   8%|▊         | 20/258 [03:46<44:54, 11.32s/it, v_num=4, loss=7.430]Epoch 0:   8%|▊         | 20/258 [03:47<45:06, 11.37s/it, v_num=4, loss=7.390]Epoch 0:   8%|▊         | 21/258 [03:58<44:52, 11.36s/it, v_num=4, loss=7.390]Epoch 0:   8%|▊         | 21/258 [03:59<45:05, 11.41s/it, v_num=4, loss=7.190]Epoch 0:   9%|▊         | 22/258 [04:13<45:23, 11.54s/it, v_num=4, loss=7.190]Epoch 0:   9%|▊         | 22/258 [04:14<45:34, 11.59s/it, v_num=4, loss=7.370]Epoch 0:   9%|▉         | 23/258 [04:29<45:52, 11.71s/it, v_num=4, loss=7.370]Epoch 0:   9%|▉         | 23/258 [04:30<46:07, 11.78s/it, v_num=4, loss=7.170]Epoch 0:   9%|▉         | 24/258 [04:41<45:42, 11.72s/it, v_num=4, loss=7.170]Epoch 0:   9%|▉         | 24/258 [04:42<45:52, 11.76s/it, v_num=4, loss=7.390]Epoch 0:  10%|▉         | 25/258 [04:51<45:20, 11.67s/it, v_num=4, loss=7.390]Epoch 0:  10%|▉         | 25/258 [04:52<45:29, 11.72s/it, v_num=4, loss=7.220]{'accelerator': 'gpu',
 'accumulate_grad_batches': 1,
 'annotation': 'data/iu_xray/annotation.json',
 'base_dir': './data/iu_xray/images',
 'batch_size': 8,
 'beam_size': 3,
 'ckpt_file': None,
 'dataset': 'iu_xray',
 'delta_file': None,
 'devices': 1,
 'diversity_penalty': 0,
 'do_sample': False,
 'end_sym': '</s>',
 'every_n_train_steps': 0,
 'freeze_vm': True,
 'global_only': False,
 'gradient_clip_val': None,
 'learning_rate': 0.0001,
 'length_penalty': 2.0,
 'limit_test_batches': 1.0,
 'limit_train_batches': 1.0,
 'limit_val_batches': 1.0,
 'llama_model': 'TinyLlama/TinyLlama-1.1B-Chat-v1.0',
 'llm_alpha': 16,
 'llm_r': 16,
 'llm_use_lora': False,
 'lora_dropout': 0.1,
 'low_resource': False,
 'max_epochs': 15,
 'max_length': 60,
 'max_new_tokens': 100,
 'min_new_tokens': 40,
 'no_repeat_ngram_size': 2,
 'num_beam_groups': 1,
 'num_nodes': 1,
 'num_sanity_val_steps': 0,
 'num_workers': 8,
 'precision': 'bf16-mixed',
 'prefetch_factor': 4,
 'repetition_penalty': 2.0,
 'savedmodel_path': './save/iu_xray/v1_shallow',
 'scorer_types': ['Bleu_4', 'CIDEr'],
 'strategy': 'auto',
 'temperature': 0,
 'test': False,
 'test_batch_size': 16,
 'val_batch_size': 12,
 'val_check_interval': 1.0,
 'validate': False,
 'vis_alpha': 16,
 'vis_r': 16,
 'vis_use_lora': False,
 'vision_model': 'microsoft/swin-base-patch4-window7-224',
 'weights': [0.5, 0.5]}
Global seed set to 42
Using bfloat16 Automatic Mixed Precision (AMP)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
Loading vision encoder:microsoft/swin-base-patch4-window7-224
/home/sandy/miniconda3/envs/success/lib/python3.9/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Some weights of the model checkpoint at microsoft/swin-base-patch4-window7-224 were not used when initializing SwinModel: ['classifier.bias', 'classifier.weight']
- This IS expected if you are initializing SwinModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing SwinModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Loading Frozen vision encoder:microsoft/swin-base-patch4-window7-224 -- Done
Loading LLAMA
Some weights of LlamaForCausalLM were not initialized from the model checkpoint at TinyLlama/TinyLlama-1.1B-Chat-v1.0 and are newly initialized: ['model.layers.14.self_attn.rotary_emb.inv_freq', 'model.layers.8.self_attn.rotary_emb.inv_freq', 'model.layers.15.self_attn.rotary_emb.inv_freq', 'model.layers.3.self_attn.rotary_emb.inv_freq', 'model.layers.19.self_attn.rotary_emb.inv_freq', 'model.layers.18.self_attn.rotary_emb.inv_freq', 'model.layers.21.self_attn.rotary_emb.inv_freq', 'model.layers.9.self_attn.rotary_emb.inv_freq', 'model.layers.0.self_attn.rotary_emb.inv_freq', 'model.layers.10.self_attn.rotary_emb.inv_freq', 'model.layers.13.self_attn.rotary_emb.inv_freq', 'model.layers.7.self_attn.rotary_emb.inv_freq', 'model.layers.4.self_attn.rotary_emb.inv_freq', 'model.layers.1.self_attn.rotary_emb.inv_freq', 'model.layers.2.self_attn.rotary_emb.inv_freq', 'model.layers.5.self_attn.rotary_emb.inv_freq', 'model.layers.16.self_attn.rotary_emb.inv_freq', 'model.layers.17.self_attn.rotary_emb.inv_freq', 'model.layers.12.self_attn.rotary_emb.inv_freq', 'model.layers.20.self_attn.rotary_emb.inv_freq', 'model.layers.6.self_attn.rotary_emb.inv_freq', 'model.layers.11.self_attn.rotary_emb.inv_freq']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of LlamaForCausalLM were not initialized from the model checkpoint at TinyLlama/TinyLlama-1.1B-Chat-v1.0 and are newly initialized because the shapes did not match:
- model.layers.0.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.0.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.1.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.1.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.10.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.10.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.11.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.11.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.12.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.12.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.13.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.13.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.14.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.14.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.15.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.15.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.16.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.16.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.17.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.17.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.18.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.18.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.19.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.19.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.2.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.2.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.20.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.20.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.21.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.21.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.3.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.3.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.4.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.4.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.5.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.5.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.6.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.6.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.7.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.7.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.8.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.8.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.9.self_attn.k_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
- model.layers.9.self_attn.v_proj.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([2048, 2048]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Loading LLAMA Done
You are using a CUDA device ('NVIDIA GeForce RTX 3060 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.
Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.
Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.
  Dataset sizes:
  Train:      2069 samples
  Validation: 296 samples
  Test:       590 samples
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name           | Type             | Params
----------------------------------------------------
0 | visual_encoder | SwinModel        | 86.7 M
1 | llama_model    | LlamaForCausalLM | 1.3 B 
2 | embed_tokens   | Embedding        | 65.5 M
3 | llama_proj     | Linear           | 2.1 M 
4 | layer_norm     | LayerNorm        | 4.1 K 
----------------------------------------------------
2.1 M     Trainable params
1.3 B     Non-trainable params
1.4 B     Total params
5,401.502 Total estimated model params size (MB)
Training: 0it [00:00, ?it/s]Training:   0%|          | 0/258 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/258 [00:00<?, ?it/s] Epoch 0:   0%|          | 1/258 [00:16<1:10:00, 16.34s/it]Epoch 0:   0%|          | 1/258 [00:16<1:10:01, 16.35s/it, v_num=5, loss=10.60]Epoch 0:   1%|          | 2/258 [00:25<54:49, 12.85s/it, v_num=5, loss=10.60]  Epoch 0:   1%|          | 2/258 [00:26<56:50, 13.32s/it, v_num=5, loss=9.870]Epoch 0:   1%|          | 3/258 [00:36<51:30, 12.12s/it, v_num=5, loss=9.870]Epoch 0:   1%|          | 3/258 [00:37<52:53, 12.44s/it, v_num=5, loss=9.380]Epoch 0:   2%|▏         | 4/258 [00:46<49:35, 11.71s/it, v_num=5, loss=9.380]Epoch 0:   2%|▏         | 4/258 [00:47<50:36, 11.96s/it, v_num=5, loss=9.200]Epoch 0:   2%|▏         | 5/258 [00:57<48:26, 11.49s/it, v_num=5, loss=9.200]Epoch 0:   2%|▏         | 5/258 [00:58<49:15, 11.68s/it, v_num=5, loss=8.830]Epoch 0:   2%|▏         | 6/258 [01:08<47:37, 11.34s/it, v_num=5, loss=8.830]Epoch 0:   2%|▏         | 6/258 [01:09<48:18, 11.50s/it, v_num=5, loss=8.710]Epoch 0:   3%|▎         | 7/258 [01:18<47:00, 11.24s/it, v_num=5, loss=8.710]Epoch 0:   3%|▎         | 7/258 [01:19<47:35, 11.38s/it, v_num=5, loss=8.210]Epoch 0:   3%|▎         | 8/258 [01:31<47:35, 11.42s/it, v_num=5, loss=8.210]Epoch 0:   3%|▎         | 8/258 [01:32<48:06, 11.54s/it, v_num=5, loss=8.380]Epoch 0:   3%|▎         | 9/258 [01:42<47:05, 11.35s/it, v_num=5, loss=8.380]Epoch 0:   3%|▎         | 9/258 [01:43<47:32, 11.46s/it, v_num=5, loss=8.440]Epoch 0:   4%|▍         | 10/258 [01:52<46:37, 11.28s/it, v_num=5, loss=8.440]Epoch 0:   4%|▍         | 10/258 [01:53<47:01, 11.38s/it, v_num=5, loss=8.140]Epoch 0:   4%|▍         | 11/258 [02:03<46:12, 11.23s/it, v_num=5, loss=8.140]Epoch 0:   4%|▍         | 11/258 [02:04<46:35, 11.32s/it, v_num=5, loss=8.020]Epoch 0:   5%|▍         | 12/258 [02:14<45:50, 11.18s/it, v_num=5, loss=8.020]Epoch 0:   5%|▍         | 12/258 [02:15<46:12, 11.27s/it, v_num=5, loss=8.030]Epoch 0:   5%|▌         | 13/258 [02:25<45:45, 11.21s/it, v_num=5, loss=8.030]Epoch 0:   5%|▌         | 13/258 [02:26<46:04, 11.28s/it, v_num=5, loss=7.640]Epoch 0:   5%|▌         | 14/258 [02:36<45:30, 11.19s/it, v_num=5, loss=7.640]Epoch 0:   5%|▌         | 14/258 [02:37<45:48, 11.26s/it, v_num=5, loss=7.830]Epoch 0:   6%|▌         | 15/258 [02:48<45:24, 11.21s/it, v_num=5, loss=7.830]Epoch 0:   6%|▌         | 15/258 [02:49<45:43, 11.29s/it, v_num=5, loss=7.410]Epoch 0:   6%|▌         | 16/258 [02:59<45:14, 11.22s/it, v_num=5, loss=7.410]Epoch 0:   6%|▌         | 16/258 [03:00<45:32, 11.29s/it, v_num=5, loss=7.530]Epoch 0:   7%|▋         | 17/258 [03:12<45:32, 11.34s/it, v_num=5, loss=7.530]Epoch 0:   7%|▋         | 17/258 [03:14<45:52, 11.42s/it, v_num=5, loss=7.500]Epoch 0:   7%|▋         | 18/258 [03:25<45:34, 11.39s/it, v_num=5, loss=7.500]Epoch 0:   7%|▋         | 18/258 [03:26<45:47, 11.45s/it, v_num=5, loss=7.450]Epoch 0:   7%|▋         | 19/258 [03:35<45:11, 11.35s/it, v_num=5, loss=7.450]Epoch 0:   7%|▋         | 19/258 [03:36<45:23, 11.40s/it, v_num=5, loss=7.430]Epoch 0:   8%|▊         | 20/258 [03:50<45:46, 11.54s/it, v_num=5, loss=7.430]Epoch 0:   8%|▊         | 20/258 [03:51<45:58, 11.59s/it, v_num=5, loss=7.390]Epoch 0:   8%|▊         | 21/258 [04:03<45:53, 11.62s/it, v_num=5, loss=7.390]Epoch 0:   8%|▊         | 21/258 [04:05<46:08, 11.68s/it, v_num=5, loss=7.190]Epoch 0:   9%|▊         | 22/258 [04:15<45:42, 11.62s/it, v_num=5, loss=7.190]Epoch 0:   9%|▊         | 22/258 [04:16<45:52, 11.66s/it, v_num=5, loss=7.370]Epoch 0:   9%|▉         | 23/258 [04:26<45:23, 11.59s/it, v_num=5, loss=7.370]Epoch 0:   9%|▉         | 23/258 [04:27<45:33, 11.63s/it, v_num=5, loss=7.170]Epoch 0:   9%|▉         | 24/258 [04:38<45:17, 11.61s/it, v_num=5, loss=7.170]Epoch 0:   9%|▉         | 24/258 [04:39<45:27, 11.66s/it, v_num=5, loss=7.390]Epoch 0:  10%|▉         | 25/258 [04:49<45:02, 11.60s/it, v_num=5, loss=7.390]Epoch 0:  10%|▉         | 25/258 [04:50<45:11, 11.64s/it, v_num=5, loss=7.220]Epoch 0:  10%|█         | 26/258 [05:03<45:08, 11.68s/it, v_num=5, loss=7.220]Epoch 0:  10%|█         | 26/258 [05:04<45:17, 11.71s/it, v_num=5, loss=7.090]Epoch 0:  10%|█         | 27/258 [05:15<44:56, 11.67s/it, v_num=5, loss=7.090]Epoch 0:  10%|█         | 27/258 [05:16<45:06, 11.71s/it, v_num=5, loss=6.820]Epoch 0:  11%|█         | 28/258 [05:27<44:48, 11.69s/it, v_num=5, loss=6.820]Epoch 0:  11%|█         | 28/258 [05:28<44:56, 11.72s/it, v_num=5, loss=7.080]Epoch 0:  11%|█         | 29/258 [05:38<44:36, 11.69s/it, v_num=5, loss=7.080]Epoch 0:  11%|█         | 29/258 [05:39<44:44, 11.72s/it, v_num=5, loss=6.960]Epoch 0:  12%|█▏        | 30/258 [05:50<44:25, 11.69s/it, v_num=5, loss=6.960]Epoch 0:  12%|█▏        | 30/258 [05:51<44:32, 11.72s/it, v_num=5, loss=7.080]Epoch 0:  12%|█▏        | 31/258 [06:02<44:14, 11.69s/it, v_num=5, loss=7.080]Epoch 0:  12%|█▏        | 31/258 [06:03<44:21, 11.72s/it, v_num=5, loss=6.870]Epoch 0:  12%|█▏        | 32/258 [06:13<43:59, 11.68s/it, v_num=5, loss=6.870]Epoch 0:  12%|█▏        | 32/258 [06:14<44:07, 11.71s/it, v_num=5, loss=6.840]Epoch 0:  13%|█▎        | 33/258 [06:24<43:44, 11.66s/it, v_num=5, loss=6.840]Epoch 0:  13%|█▎        | 33/258 [06:25<43:50, 11.69s/it, v_num=5, loss=6.560]Epoch 0:  13%|█▎        | 34/258 [06:35<43:26, 11.64s/it, v_num=5, loss=6.560]Epoch 0:  13%|█▎        | 34/258 [06:36<43:33, 11.67s/it, v_num=5, loss=7.010]Epoch 0:  14%|█▎        | 35/258 [06:46<43:11, 11.62s/it, v_num=5, loss=7.010]Epoch 0:  14%|█▎        | 35/258 [06:47<43:18, 11.65s/it, v_num=5, loss=6.810]Epoch 0:  14%|█▍        | 36/258 [06:57<42:57, 11.61s/it, v_num=5, loss=6.810]Epoch 0:  14%|█▍        | 36/258 [06:59<43:04, 11.64s/it, v_num=5, loss=6.760]Epoch 0:  14%|█▍        | 37/258 [07:09<42:46, 11.61s/it, v_num=5, loss=6.760]Epoch 0:  14%|█▍        | 37/258 [07:10<42:53, 11.65s/it, v_num=5, loss=6.600]Epoch 0:  15%|█▍        | 38/258 [07:21<42:34, 11.61s/it, v_num=5, loss=6.600]Epoch 0:  15%|█▍        | 38/258 [07:22<42:39, 11.64s/it, v_num=5, loss=6.870]Epoch 0:  15%|█▌        | 39/258 [07:32<42:19, 11.59s/it, v_num=5, loss=6.870]Epoch 0:  15%|█▌        | 39/258 [07:33<42:24, 11.62s/it, v_num=5, loss=6.200]Epoch 0:  16%|█▌        | 40/258 [07:43<42:08, 11.60s/it, v_num=5, loss=6.200]Epoch 0:  16%|█▌        | 40/258 [07:44<42:13, 11.62s/it, v_num=5, loss=6.280]Epoch 0:  16%|█▌        | 41/258 [07:55<41:56, 11.59s/it, v_num=5, loss=6.280]Epoch 0:  16%|█▌        | 41/258 [07:56<42:03, 11.63s/it, v_num=5, loss=6.550]Epoch 0:  16%|█▋        | 42/258 [08:08<41:54, 11.64s/it, v_num=5, loss=6.550]Epoch 0:  16%|█▋        | 42/258 [08:10<42:01, 11.67s/it, v_num=5, loss=6.610]Epoch 0:  17%|█▋        | 43/258 [08:21<41:48, 11.67s/it, v_num=5, loss=6.610]Epoch 0:  17%|█▋        | 43/258 [08:22<41:53, 11.69s/it, v_num=5, loss=6.520]Epoch 0:  17%|█▋        | 44/258 [08:32<41:33, 11.65s/it, v_num=5, loss=6.520]Epoch 0:  17%|█▋        | 44/258 [08:33<41:39, 11.68s/it, v_num=5, loss=6.900]Epoch 0:  17%|█▋        | 45/258 [08:44<41:22, 11.66s/it, v_num=5, loss=6.900]Epoch 0:  17%|█▋        | 45/258 [08:45<41:28, 11.68s/it, v_num=5, loss=6.330]Epoch 0:  18%|█▊        | 46/258 [08:55<41:09, 11.65s/it, v_num=5, loss=6.330]Epoch 0:  18%|█▊        | 46/258 [08:56<41:13, 11.67s/it, v_num=5, loss=6.160]Epoch 0:  18%|█▊        | 47/258 [09:06<40:53, 11.63s/it, v_num=5, loss=6.160]Epoch 0:  18%|█▊        | 47/258 [09:07<40:58, 11.65s/it, v_num=5, loss=5.910]Epoch 0:  19%|█▊        | 48/258 [09:17<40:41, 11.62s/it, v_num=5, loss=5.910]Epoch 0:  19%|█▊        | 48/258 [09:19<40:45, 11.65s/it, v_num=5, loss=6.480]Epoch 0:  19%|█▉        | 49/258 [09:29<40:28, 11.62s/it, v_num=5, loss=6.480]Epoch 0:  19%|█▉        | 49/258 [09:30<40:32, 11.64s/it, v_num=5, loss=6.400]Epoch 0:  19%|█▉        | 50/258 [09:40<40:16, 11.62s/it, v_num=5, loss=6.400]Epoch 0:  19%|█▉        | 50/258 [09:41<40:20, 11.64s/it, v_num=5, loss=5.890]Epoch 0:  20%|█▉        | 51/258 [09:51<40:00, 11.60s/it, v_num=5, loss=5.890]Epoch 0:  20%|█▉        | 51/258 [09:52<40:04, 11.62s/it, v_num=5, loss=5.980]Epoch 0:  20%|██        | 52/258 [10:02<39:44, 11.58s/it, v_num=5, loss=5.980]Epoch 0:  20%|██        | 52/258 [10:02<39:48, 11.60s/it, v_num=5, loss=6.010]Epoch 0:  21%|██        | 53/258 [10:12<39:29, 11.56s/it, v_num=5, loss=6.010]Epoch 0:  21%|██        | 53/258 [10:13<39:33, 11.58s/it, v_num=5, loss=6.010]Epoch 0:  21%|██        | 54/258 [10:23<39:15, 11.54s/it, v_num=5, loss=6.010]Epoch 0:  21%|██        | 54/258 [10:24<39:18, 11.56s/it, v_num=5, loss=6.040]Epoch 0:  21%|██▏       | 55/258 [10:33<38:59, 11.52s/it, v_num=5, loss=6.040]Epoch 0:  21%|██▏       | 55/258 [10:34<39:02, 11.54s/it, v_num=5, loss=6.220]Epoch 0:  22%|██▏       | 56/258 [10:44<38:44, 11.51s/it, v_num=5, loss=6.220]Epoch 0:  22%|██▏       | 56/258 [10:45<38:47, 11.52s/it, v_num=5, loss=6.180]Epoch 0:  22%|██▏       | 57/258 [10:54<38:29, 11.49s/it, v_num=5, loss=6.180]Epoch 0:  22%|██▏       | 57/258 [10:55<38:32, 11.51s/it, v_num=5, loss=6.070]Epoch 0:  22%|██▏       | 58/258 [11:05<38:14, 11.47s/it, v_num=5, loss=6.070]Epoch 0:  22%|██▏       | 58/258 [11:06<38:17, 11.49s/it, v_num=5, loss=6.040]Epoch 0:  23%|██▎       | 59/258 [11:15<37:59, 11.46s/it, v_num=5, loss=6.040]Epoch 0:  23%|██▎       | 59/258 [11:16<38:03, 11.47s/it, v_num=5, loss=6.070]Epoch 0:  23%|██▎       | 60/258 [11:26<37:45, 11.44s/it, v_num=5, loss=6.070]Epoch 0:  23%|██▎       | 60/258 [11:27<37:48, 11.46s/it, v_num=5, loss=5.610]Epoch 0:  24%|██▎       | 61/258 [11:36<37:30, 11.42s/it, v_num=5, loss=5.610]Epoch 0:  24%|██▎       | 61/258 [11:37<37:33, 11.44s/it, v_num=5, loss=5.780]Epoch 0:  24%|██▍       | 62/258 [11:47<37:16, 11.41s/it, v_num=5, loss=5.780]Epoch 0:  24%|██▍       | 62/258 [11:48<37:19, 11.43s/it, v_num=5, loss=5.900]Epoch 0:  24%|██▍       | 63/258 [11:58<37:02, 11.40s/it, v_num=5, loss=5.900]Epoch 0:  24%|██▍       | 63/258 [11:59<37:05, 11.41s/it, v_num=5, loss=5.820]Epoch 0:  25%|██▍       | 64/258 [12:08<36:48, 11.38s/it, v_num=5, loss=5.820]Epoch 0:  25%|██▍       | 64/258 [12:09<36:51, 11.40s/it, v_num=5, loss=6.030]Epoch 0:  25%|██▌       | 65/258 [12:19<36:34, 11.37s/it, v_num=5, loss=6.030]Epoch 0:  25%|██▌       | 65/258 [12:19<36:37, 11.38s/it, v_num=5, loss=5.880]Epoch 0:  26%|██▌       | 66/258 [12:29<36:20, 11.36s/it, v_num=5, loss=5.880]Epoch 0:  26%|██▌       | 66/258 [12:30<36:23, 11.37s/it, v_num=5, loss=5.680]Epoch 0:  26%|██▌       | 67/258 [12:39<36:06, 11.34s/it, v_num=5, loss=5.680]Epoch 0:  26%|██▌       | 67/258 [12:40<36:09, 11.36s/it, v_num=5, loss=6.270]Epoch 0:  26%|██▋       | 68/258 [12:50<35:53, 11.33s/it, v_num=5, loss=6.270]Epoch 0:  26%|██▋       | 68/258 [12:51<35:56, 11.35s/it, v_num=5, loss=5.550]Epoch 0:  27%|██▋       | 69/258 [13:01<35:40, 11.32s/it, v_num=5, loss=5.550]Epoch 0:  27%|██▋       | 69/258 [13:02<35:42, 11.34s/it, v_num=5, loss=5.990]Epoch 0:  27%|██▋       | 70/258 [13:11<35:26, 11.31s/it, v_num=5, loss=5.990]Epoch 0:  27%|██▋       | 70/258 [13:12<35:29, 11.32s/it, v_num=5, loss=5.580]Epoch 0:  28%|██▊       | 71/258 [13:22<35:13, 11.30s/it, v_num=5, loss=5.580]Epoch 0:  28%|██▊       | 71/258 [13:23<35:15, 11.31s/it, v_num=5, loss=5.590]Epoch 0:  28%|██▊       | 72/258 [13:32<34:59, 11.29s/it, v_num=5, loss=5.590]Epoch 0:  28%|██▊       | 72/258 [13:33<35:02, 11.30s/it, v_num=5, loss=6.180]Epoch 0:  28%|██▊       | 73/258 [13:43<34:46, 11.28s/it, v_num=5, loss=6.180]Epoch 0:  28%|██▊       | 73/258 [13:44<34:49, 11.29s/it, v_num=5, loss=5.940]Epoch 0:  29%|██▊       | 74/258 [13:54<34:35, 11.28s/it, v_num=5, loss=5.940]Epoch 0:  29%|██▊       | 74/258 [13:55<34:38, 11.30s/it, v_num=5, loss=5.820]Epoch 0:  29%|██▉       | 75/258 [14:06<34:24, 11.28s/it, v_num=5, loss=5.820]Epoch 0:  29%|██▉       | 75/258 [14:07<34:27, 11.30s/it, v_num=5, loss=5.720]Epoch 0:  29%|██▉       | 76/258 [14:16<34:11, 11.27s/it, v_num=5, loss=5.720]Epoch 0:  29%|██▉       | 76/258 [14:17<34:14, 11.29s/it, v_num=5, loss=5.630]Epoch 0:  30%|██▉       | 77/258 [14:27<33:59, 11.27s/it, v_num=5, loss=5.630]Epoch 0:  30%|██▉       | 77/258 [14:28<34:02, 11.28s/it, v_num=5, loss=5.880]Epoch 0:  30%|███       | 78/258 [14:39<33:50, 11.28s/it, v_num=5, loss=5.880]Epoch 0:  30%|███       | 78/258 [14:40<33:52, 11.29s/it, v_num=5, loss=5.540]Epoch 0:  31%|███       | 79/258 [14:51<33:38, 11.28s/it, v_num=5, loss=5.540]Epoch 0:  31%|███       | 79/258 [14:52<33:41, 11.29s/it, v_num=5, loss=5.720]Epoch 0:  31%|███       | 80/258 [15:02<33:27, 11.28s/it, v_num=5, loss=5.720]Epoch 0:  31%|███       | 80/258 [15:03<33:29, 11.29s/it, v_num=5, loss=5.220]Epoch 0:  31%|███▏      | 81/258 [15:13<33:16, 11.28s/it, v_num=5, loss=5.220]Epoch 0:  31%|███▏      | 81/258 [15:14<33:18, 11.29s/it, v_num=5, loss=6.180]Epoch 0:  32%|███▏      | 82/258 [15:25<33:05, 11.28s/it, v_num=5, loss=6.180]Epoch 0:  32%|███▏      | 82/258 [15:26<33:07, 11.29s/it, v_num=5, loss=5.180]Epoch 0:  32%|███▏      | 83/258 [15:36<32:54, 11.28s/it, v_num=5, loss=5.180]Epoch 0:  32%|███▏      | 83/258 [15:37<32:56, 11.29s/it, v_num=5, loss=6.180]Epoch 0:  33%|███▎      | 84/258 [15:47<32:43, 11.28s/it, v_num=5, loss=6.180]Epoch 0:  33%|███▎      | 84/258 [15:49<32:45, 11.30s/it, v_num=5, loss=5.270]Epoch 0:  33%|███▎      | 85/258 [15:59<32:32, 11.29s/it, v_num=5, loss=5.270]Epoch 0:  33%|███▎      | 85/258 [16:00<32:34, 11.30s/it, v_num=5, loss=5.740]Epoch 0:  33%|███▎      | 86/258 [16:10<32:21, 11.29s/it, v_num=5, loss=5.740]Epoch 0:  33%|███▎      | 86/258 [16:11<32:23, 11.30s/it, v_num=5, loss=5.380]Epoch 0:  34%|███▎      | 87/258 [16:22<32:10, 11.29s/it, v_num=5, loss=5.380]Epoch 0:  34%|███▎      | 87/258 [16:23<32:12, 11.30s/it, v_num=5, loss=5.810]Epoch 0:  34%|███▍      | 88/258 [16:33<31:58, 11.28s/it, v_num=5, loss=5.810]Epoch 0:  34%|███▍      | 88/258 [16:34<32:00, 11.30s/it, v_num=5, loss=5.630]Epoch 0:  34%|███▍      | 89/258 [16:44<31:48, 11.29s/it, v_num=5, loss=5.630]Epoch 0:  34%|███▍      | 89/258 [16:45<31:50, 11.30s/it, v_num=5, loss=4.880]Epoch 0:  35%|███▍      | 90/258 [16:55<31:36, 11.29s/it, v_num=5, loss=4.880]Epoch 0:  35%|███▍      | 90/258 [16:56<31:38, 11.30s/it, v_num=5, loss=5.790]Epoch 0:  35%|███▌      | 91/258 [17:07<31:26, 11.29s/it, v_num=5, loss=5.790]Epoch 0:  35%|███▌      | 91/258 [17:08<31:28, 11.31s/it, v_num=5, loss=5.900]Epoch 0:  36%|███▌      | 92/258 [17:19<31:14, 11.29s/it, v_num=5, loss=5.900]Epoch 0:  36%|███▌      | 92/258 [17:20<31:16, 11.31s/it, v_num=5, loss=5.900]Epoch 0:  36%|███▌      | 93/258 [17:30<31:02, 11.29s/it, v_num=5, loss=5.900]Epoch 0:  36%|███▌      | 93/258 [17:31<31:04, 11.30s/it, v_num=5, loss=5.690]Epoch 0:  36%|███▋      | 94/258 [17:41<30:52, 11.30s/it, v_num=5, loss=5.690]Epoch 0:  36%|███▋      | 94/258 [17:42<30:54, 11.31s/it, v_num=5, loss=5.630]Epoch 0:  37%|███▋      | 95/258 [17:53<30:42, 11.30s/it, v_num=5, loss=5.630]Epoch 0:  37%|███▋      | 95/258 [17:55<30:44, 11.32s/it, v_num=5, loss=5.670]Epoch 0:  37%|███▋      | 96/258 [18:07<30:34, 11.32s/it, v_num=5, loss=5.670]Epoch 0:  37%|███▋      | 96/258 [18:08<30:36, 11.33s/it, v_num=5, loss=5.440]Epoch 0:  38%|███▊      | 97/258 [18:18<30:22, 11.32s/it, v_num=5, loss=5.440]Epoch 0:  38%|███▊      | 97/258 [18:19<30:24, 11.33s/it, v_num=5, loss=5.990]Epoch 0:  38%|███▊      | 98/258 [18:29<30:10, 11.32s/it, v_num=5, loss=5.990]Epoch 0:  38%|███▊      | 98/258 [18:29<30:12, 11.33s/it, v_num=5, loss=5.580]Epoch 0:  38%|███▊      | 99/258 [18:39<29:58, 11.31s/it, v_num=5, loss=5.580]Epoch 0:  38%|███▊      | 99/258 [18:40<30:00, 11.32s/it, v_num=5, loss=5.410]Epoch 0:  39%|███▉      | 100/258 [18:50<29:46, 11.31s/it, v_num=5, loss=5.410]Epoch 0:  39%|███▉      | 100/258 [18:51<29:48, 11.32s/it, v_num=5, loss=5.730]Epoch 0:  39%|███▉      | 101/258 [19:01<29:34, 11.30s/it, v_num=5, loss=5.730]Epoch 0:  39%|███▉      | 101/258 [19:02<29:35, 11.31s/it, v_num=5, loss=5.330]Epoch 0:  40%|███▉      | 102/258 [19:11<29:21, 11.29s/it, v_num=5, loss=5.330]Epoch 0:  40%|███▉      | 102/258 [19:12<29:23, 11.30s/it, v_num=5, loss=5.470]Epoch 0:  40%|███▉      | 103/258 [19:22<29:09, 11.29s/it, v_num=5, loss=5.470]Epoch 0:  40%|███▉      | 103/258 [19:23<29:11, 11.30s/it, v_num=5, loss=5.460]Epoch 0:  40%|████      | 104/258 [19:36<29:01, 11.31s/it, v_num=5, loss=5.460]Epoch 0:  40%|████      | 104/258 [19:37<29:03, 11.32s/it, v_num=5, loss=5.120]Epoch 0:  41%|████      | 105/258 [19:47<28:50, 11.31s/it, v_num=5, loss=5.120]Epoch 0:  41%|████      | 105/258 [19:48<28:51, 11.32s/it, v_num=5, loss=5.030]Epoch 0:  41%|████      | 106/258 [19:58<28:38, 11.30s/it, v_num=5, loss=5.030]Epoch 0:  41%|████      | 106/258 [19:59<28:39, 11.31s/it, v_num=5, loss=5.360]Epoch 0:  41%|████▏     | 107/258 [20:09<28:26, 11.30s/it, v_num=5, loss=5.360]Epoch 0:  41%|████▏     | 107/258 [20:10<28:27, 11.31s/it, v_num=5, loss=5.790]Epoch 0:  42%|████▏     | 108/258 [20:19<28:14, 11.30s/it, v_num=5, loss=5.790]Epoch 0:  42%|████▏     | 108/258 [20:20<28:15, 11.30s/it, v_num=5, loss=5.850]Epoch 0:  42%|████▏     | 109/258 [20:30<28:02, 11.29s/it, v_num=5, loss=5.850]Epoch 0:  42%|████▏     | 109/258 [20:31<28:03, 11.30s/it, v_num=5, loss=5.820]Epoch 0:  43%|████▎     | 110/258 [20:41<27:50, 11.29s/it, v_num=5, loss=5.820]Epoch 0:  43%|████▎     | 110/258 [20:42<27:51, 11.30s/it, v_num=5, loss=5.670]Epoch 0:  43%|████▎     | 111/258 [20:52<27:38, 11.28s/it, v_num=5, loss=5.670]Epoch 0:  43%|████▎     | 111/258 [20:53<27:39, 11.29s/it, v_num=5, loss=5.320]Epoch 0:  43%|████▎     | 112/258 [21:03<27:27, 11.28s/it, v_num=5, loss=5.320]Epoch 0:  43%|████▎     | 112/258 [21:04<27:28, 11.29s/it, v_num=5, loss=5.390]Epoch 0:  44%|████▍     | 113/258 [21:14<27:15, 11.28s/it, v_num=5, loss=5.390]Epoch 0:  44%|████▍     | 113/258 [21:15<27:16, 11.29s/it, v_num=5, loss=5.870]Epoch 0:  44%|████▍     | 114/258 [21:25<27:03, 11.28s/it, v_num=5, loss=5.870]Epoch 0:  44%|████▍     | 114/258 [21:26<27:05, 11.29s/it, v_num=5, loss=6.070]Epoch 0:  45%|████▍     | 115/258 [21:36<26:52, 11.27s/it, v_num=5, loss=6.070]Epoch 0:  45%|████▍     | 115/258 [21:37<26:53, 11.28s/it, v_num=5, loss=5.490]Epoch 0:  45%|████▍     | 116/258 [21:49<26:42, 11.29s/it, v_num=5, loss=5.490]Epoch 0:  45%|████▍     | 116/258 [21:50<26:44, 11.30s/it, v_num=5, loss=5.510]Epoch 0:  45%|████▌     | 117/258 [22:00<26:31, 11.29s/it, v_num=5, loss=5.510]Epoch 0:  45%|████▌     | 117/258 [22:01<26:32, 11.29s/it, v_num=5, loss=5.100]Epoch 0:  46%|████▌     | 118/258 [22:11<26:19, 11.28s/it, v_num=5, loss=5.100]Epoch 0:  46%|████▌     | 118/258 [22:12<26:20, 11.29s/it, v_num=5, loss=5.320]Epoch 0:  46%|████▌     | 119/258 [22:21<26:07, 11.28s/it, v_num=5, loss=5.320]Epoch 0:  46%|████▌     | 119/258 [22:22<26:08, 11.29s/it, v_num=5, loss=5.190]Epoch 0:  47%|████▋     | 120/258 [22:32<25:55, 11.27s/it, v_num=5, loss=5.190]Epoch 0:  47%|████▋     | 120/258 [22:33<25:56, 11.28s/it, v_num=5, loss=5.460]Epoch 0:  47%|████▋     | 121/258 [22:43<25:43, 11.27s/it, v_num=5, loss=5.460]Epoch 0:  47%|████▋     | 121/258 [22:44<25:45, 11.28s/it, v_num=5, loss=5.420]Epoch 0:  47%|████▋     | 122/258 [22:56<25:34, 11.28s/it, v_num=5, loss=5.420]Epoch 0:  47%|████▋     | 122/258 [22:57<25:35, 11.29s/it, v_num=5, loss=5.900]Epoch 0:  48%|████▊     | 123/258 [23:07<25:22, 11.28s/it, v_num=5, loss=5.900]Epoch 0:  48%|████▊     | 123/258 [23:08<25:23, 11.29s/it, v_num=5, loss=5.820]Epoch 0:  48%|████▊     | 124/258 [23:18<25:11, 11.28s/it, v_num=5, loss=5.820]Epoch 0:  48%|████▊     | 124/258 [23:19<25:12, 11.28s/it, v_num=5, loss=5.580]Epoch 0:  48%|████▊     | 125/258 [23:29<24:59, 11.27s/it, v_num=5, loss=5.580]Epoch 0:  48%|████▊     | 125/258 [23:30<25:00, 11.28s/it, v_num=5, loss=5.310]Epoch 0:  49%|████▉     | 126/258 [23:40<24:48, 11.27s/it, v_num=5, loss=5.310]Epoch 0:  49%|████▉     | 126/258 [23:41<24:49, 11.28s/it, v_num=5, loss=4.960]Epoch 0:  49%|████▉     | 127/258 [23:51<24:36, 11.27s/it, v_num=5, loss=4.960]Epoch 0:  49%|████▉     | 127/258 [23:52<24:37, 11.28s/it, v_num=5, loss=5.260]Epoch 0:  50%|████▉     | 128/258 [24:02<24:24, 11.27s/it, v_num=5, loss=5.260]Epoch 0:  50%|████▉     | 128/258 [24:03<24:25, 11.28s/it, v_num=5, loss=5.050]Epoch 0:  50%|█████     | 129/258 [24:13<24:13, 11.26s/it, v_num=5, loss=5.050]Epoch 0:  50%|█████     | 129/258 [24:14<24:14, 11.27s/it, v_num=5, loss=4.960]Epoch 0:  50%|█████     | 130/258 [24:24<24:01, 11.26s/it, v_num=5, loss=4.960]Epoch 0:  50%|█████     | 130/258 [24:25<24:02, 11.27s/it, v_num=5, loss=5.490]Epoch 0:  51%|█████     | 131/258 [24:35<23:50, 11.26s/it, v_num=5, loss=5.490]Epoch 0:  51%|█████     | 131/258 [24:36<23:51, 11.27s/it, v_num=5, loss=5.410]Epoch 0:  51%|█████     | 132/258 [24:47<23:39, 11.27s/it, v_num=5, loss=5.410]Epoch 0:  51%|█████     | 132/258 [24:48<23:40, 11.28s/it, v_num=5, loss=5.460]Epoch 0:  52%|█████▏    | 133/258 [24:58<23:28, 11.27s/it, v_num=5, loss=5.460]Epoch 0:  52%|█████▏    | 133/258 [24:59<23:29, 11.28s/it, v_num=5, loss=5.200]Epoch 0:  52%|█████▏    | 134/258 [25:09<23:16, 11.27s/it, v_num=5, loss=5.200]Epoch 0:  52%|█████▏    | 134/258 [25:10<23:17, 11.27s/it, v_num=5, loss=5.650]Epoch 0:  52%|█████▏    | 135/258 [25:21<23:06, 11.27s/it, v_num=5, loss=5.650]Epoch 0:  52%|█████▏    | 135/258 [25:22<23:07, 11.28s/it, v_num=5, loss=5.080]Epoch 0:  53%|█████▎    | 136/258 [25:32<22:54, 11.27s/it, v_num=5, loss=5.080]Epoch 0:  53%|█████▎    | 136/258 [25:33<22:55, 11.27s/it, v_num=5, loss=5.370]Epoch 0:  53%|█████▎    | 137/258 [25:43<22:43, 11.27s/it, v_num=5, loss=5.370]Epoch 0:  53%|█████▎    | 137/258 [25:44<22:44, 11.28s/it, v_num=5, loss=5.710]Epoch 0:  53%|█████▎    | 138/258 [25:54<22:31, 11.27s/it, v_num=5, loss=5.710]Epoch 0:  53%|█████▎    | 138/258 [25:55<22:32, 11.27s/it, v_num=5, loss=5.030]Epoch 0:  54%|█████▍    | 139/258 [26:05<22:20, 11.27s/it, v_num=5, loss=5.030]Epoch 0:  54%|█████▍    | 139/258 [26:07<22:21, 11.27s/it, v_num=5, loss=5.390]Epoch 0:  54%|█████▍    | 140/258 [26:17<22:09, 11.26s/it, v_num=5, loss=5.390]Epoch 0:  54%|█████▍    | 140/258 [26:18<22:10, 11.27s/it, v_num=5, loss=5.470]Epoch 0:  55%|█████▍    | 141/258 [26:28<21:57, 11.26s/it, v_num=5, loss=5.470]Epoch 0:  55%|█████▍    | 141/258 [26:29<21:58, 11.27s/it, v_num=5, loss=5.450]Epoch 0:  55%|█████▌    | 142/258 [26:38<21:46, 11.26s/it, v_num=5, loss=5.450]Epoch 0:  55%|█████▌    | 142/258 [26:39<21:46, 11.27s/it, v_num=5, loss=5.130]Epoch 0:  55%|█████▌    | 143/258 [26:49<21:34, 11.26s/it, v_num=5, loss=5.130]Epoch 0:  55%|█████▌    | 143/258 [26:50<21:35, 11.27s/it, v_num=5, loss=4.740]Epoch 0:  56%|█████▌    | 144/258 [27:00<21:23, 11.26s/it, v_num=5, loss=4.740]Epoch 0:  56%|█████▌    | 144/258 [27:01<21:24, 11.26s/it, v_num=5, loss=5.810]Epoch 0:  56%|█████▌    | 145/258 [27:11<21:11, 11.25s/it, v_num=5, loss=5.810]Epoch 0:  56%|█████▌    | 145/258 [27:12<21:12, 11.26s/it, v_num=5, loss=5.200]Epoch 0:  57%|█████▋    | 146/258 [27:23<21:01, 11.26s/it, v_num=5, loss=5.200]Epoch 0:  57%|█████▋    | 146/258 [27:24<21:01, 11.27s/it, v_num=5, loss=5.120]Epoch 0:  57%|█████▋    | 147/258 [27:34<20:49, 11.26s/it, v_num=5, loss=5.120]Epoch 0:  57%|█████▋    | 147/258 [27:35<20:50, 11.26s/it, v_num=5, loss=5.060]Epoch 0:  57%|█████▋    | 148/258 [27:45<20:38, 11.26s/it, v_num=5, loss=5.060]Epoch 0:  57%|█████▋    | 148/258 [27:46<20:38, 11.26s/it, v_num=5, loss=5.350]Epoch 0:  58%|█████▊    | 149/258 [27:56<20:26, 11.25s/it, v_num=5, loss=5.350]Epoch 0:  58%|█████▊    | 149/258 [27:57<20:27, 11.26s/it, v_num=5, loss=5.560]Epoch 0:  58%|█████▊    | 150/258 [28:08<20:15, 11.26s/it, v_num=5, loss=5.560]Epoch 0:  58%|█████▊    | 150/258 [28:09<20:16, 11.27s/it, v_num=5, loss=5.540]Epoch 0:  59%|█████▊    | 151/258 [28:20<20:04, 11.26s/it, v_num=5, loss=5.540]Epoch 0:  59%|█████▊    | 151/258 [28:21<20:05, 11.27s/it, v_num=5, loss=5.120]Epoch 0:  59%|█████▉    | 152/258 [28:31<19:53, 11.26s/it, v_num=5, loss=5.120]Epoch 0:  59%|█████▉    | 152/258 [28:32<19:54, 11.27s/it, v_num=5, loss=5.310]Epoch 0:  59%|█████▉    | 153/258 [28:42<19:42, 11.26s/it, v_num=5, loss=5.310]Epoch 0:  59%|█████▉    | 153/258 [28:43<19:42, 11.27s/it, v_num=5, loss=5.130]Epoch 0:  60%|█████▉    | 154/258 [28:53<19:30, 11.26s/it, v_num=5, loss=5.130]Epoch 0:  60%|█████▉    | 154/258 [28:54<19:31, 11.27s/it, v_num=5, loss=5.060]Epoch 0:  60%|██████    | 155/258 [29:04<19:19, 11.26s/it, v_num=5, loss=5.060]Epoch 0:  60%|██████    | 155/258 [29:05<19:20, 11.26s/it, v_num=5, loss=5.570]Epoch 0:  60%|██████    | 156/258 [29:16<19:08, 11.26s/it, v_num=5, loss=5.570]Epoch 0:  60%|██████    | 156/258 [29:17<19:08, 11.26s/it, v_num=5, loss=5.010]Epoch 0:  61%|██████    | 157/258 [29:28<18:57, 11.27s/it, v_num=5, loss=5.010]Epoch 0:  61%|██████    | 157/258 [29:29<18:58, 11.27s/it, v_num=5, loss=5.380]Epoch 0:  61%|██████    | 158/258 [29:40<18:46, 11.27s/it, v_num=5, loss=5.380]Epoch 0:  61%|██████    | 158/258 [29:41<18:47, 11.28s/it, v_num=5, loss=5.060]Epoch 0:  62%|██████▏   | 159/258 [29:52<18:36, 11.28s/it, v_num=5, loss=5.060]Epoch 0:  62%|██████▏   | 159/258 [29:54<18:37, 11.28s/it, v_num=5, loss=5.080]Epoch 0:  62%|██████▏   | 160/258 [30:04<18:24, 11.28s/it, v_num=5, loss=5.080]Epoch 0:  62%|██████▏   | 160/258 [30:05<18:25, 11.28s/it, v_num=5, loss=5.770]Epoch 0:  62%|██████▏   | 161/258 [30:15<18:13, 11.27s/it, v_num=5, loss=5.770]Epoch 0:  62%|██████▏   | 161/258 [30:16<18:14, 11.28s/it, v_num=5, loss=5.260]Epoch 0:  63%|██████▎   | 162/258 [30:26<18:02, 11.28s/it, v_num=5, loss=5.260]Epoch 0:  63%|██████▎   | 162/258 [30:27<18:03, 11.28s/it, v_num=5, loss=5.470]Epoch 0:  63%|██████▎   | 163/258 [30:37<17:51, 11.27s/it, v_num=5, loss=5.470]Epoch 0:  63%|██████▎   | 163/258 [30:38<17:51, 11.28s/it, v_num=5, loss=5.240]Epoch 0:  64%|██████▎   | 164/258 [30:48<17:39, 11.27s/it, v_num=5, loss=5.240]Epoch 0:  64%|██████▎   | 164/258 [30:49<17:39, 11.28s/it, v_num=5, loss=5.040]Epoch 0:  64%|██████▍   | 165/258 [30:58<17:27, 11.27s/it, v_num=5, loss=5.040]Epoch 0:  64%|██████▍   | 165/258 [30:59<17:28, 11.27s/it, v_num=5, loss=5.210]Epoch 0:  64%|██████▍   | 166/258 [31:10<17:16, 11.27s/it, v_num=5, loss=5.210]Epoch 0:  64%|██████▍   | 166/258 [31:12<17:17, 11.28s/it, v_num=5, loss=5.120]Epoch 0:  65%|██████▍   | 167/258 [31:23<17:06, 11.28s/it, v_num=5, loss=5.120]Epoch 0:  65%|██████▍   | 167/258 [31:24<17:06, 11.28s/it, v_num=5, loss=5.840]Epoch 0:  65%|██████▌   | 168/258 [31:34<16:55, 11.28s/it, v_num=5, loss=5.840]Epoch 0:  65%|██████▌   | 168/258 [31:35<16:55, 11.29s/it, v_num=5, loss=5.120]Epoch 0:  66%|██████▌   | 169/258 [31:47<16:44, 11.29s/it, v_num=5, loss=5.120]Epoch 0:  66%|██████▌   | 169/258 [31:49<16:45, 11.30s/it, v_num=5, loss=5.150]Epoch 0:  66%|██████▌   | 170/258 [32:00<16:33, 11.30s/it, v_num=5, loss=5.150]Epoch 0:  66%|██████▌   | 170/258 [32:01<16:34, 11.30s/it, v_num=5, loss=5.300]Epoch 0:  66%|██████▋   | 171/258 [32:11<16:22, 11.29s/it, v_num=5, loss=5.300]Epoch 0:  66%|██████▋   | 171/258 [32:12<16:23, 11.30s/it, v_num=5, loss=5.630]Epoch 0:  67%|██████▋   | 172/258 [32:22<16:11, 11.29s/it, v_num=5, loss=5.630]Epoch 0:  67%|██████▋   | 172/258 [32:23<16:11, 11.30s/it, v_num=5, loss=5.350]Epoch 0:  67%|██████▋   | 173/258 [32:33<15:59, 11.29s/it, v_num=5, loss=5.350]Epoch 0:  67%|██████▋   | 173/258 [32:34<16:00, 11.30s/it, v_num=5, loss=4.970]Epoch 0:  67%|██████▋   | 174/258 [32:45<15:48, 11.30s/it, v_num=5, loss=4.970]Epoch 0:  67%|██████▋   | 174/258 [32:46<15:49, 11.30s/it, v_num=5, loss=5.400]Epoch 0:  68%|██████▊   | 175/258 [32:57<15:37, 11.30s/it, v_num=5, loss=5.400]Epoch 0:  68%|██████▊   | 175/258 [32:58<15:38, 11.30s/it, v_num=5, loss=4.850]Epoch 0:  68%|██████▊   | 176/258 [33:08<15:26, 11.30s/it, v_num=5, loss=4.850]Epoch 0:  68%|██████▊   | 176/258 [33:09<15:26, 11.30s/it, v_num=5, loss=5.190]Epoch 0:  69%|██████▊   | 177/258 [33:20<15:15, 11.30s/it, v_num=5, loss=5.190]Epoch 0:  69%|██████▊   | 177/258 [33:21<15:15, 11.31s/it, v_num=5, loss=5.010]Epoch 0:  69%|██████▉   | 178/258 [33:31<15:04, 11.30s/it, v_num=5, loss=5.010]Epoch 0:  69%|██████▉   | 178/258 [33:32<15:04, 11.31s/it, v_num=5, loss=4.980]Epoch 0:  69%|██████▉   | 179/258 [33:43<14:52, 11.30s/it, v_num=5, loss=4.980]Epoch 0:  69%|██████▉   | 179/258 [33:44<14:53, 11.31s/it, v_num=5, loss=5.240]Epoch 0:  70%|██████▉   | 180/258 [33:55<14:42, 11.31s/it, v_num=5, loss=5.240]Epoch 0:  70%|██████▉   | 180/258 [33:56<14:42, 11.31s/it, v_num=5, loss=5.230]Epoch 0:  70%|███████   | 181/258 [34:06<14:30, 11.31s/it, v_num=5, loss=5.230]Epoch 0:  70%|███████   | 181/258 [34:07<14:31, 11.31s/it, v_num=5, loss=5.290]Epoch 0:  71%|███████   | 182/258 [34:17<14:19, 11.31s/it, v_num=5, loss=5.290]Epoch 0:  71%|███████   | 182/258 [34:18<14:19, 11.31s/it, v_num=5, loss=5.220]Epoch 0:  71%|███████   | 183/258 [34:29<14:08, 11.31s/it, v_num=5, loss=5.220]Epoch 0:  71%|███████   | 183/258 [34:30<14:08, 11.31s/it, v_num=5, loss=5.380]Epoch 0:  71%|███████▏  | 184/258 [34:40<13:56, 11.31s/it, v_num=5, loss=5.380]Epoch 0:  71%|███████▏  | 184/258 [34:41<13:57, 11.31s/it, v_num=5, loss=5.000]Epoch 0:  72%|███████▏  | 185/258 [34:52<13:45, 11.31s/it, v_num=5, loss=5.000]Epoch 0:  72%|███████▏  | 185/258 [34:53<13:46, 11.32s/it, v_num=5, loss=5.490]Epoch 0:  72%|███████▏  | 186/258 [35:05<13:34, 11.32s/it, v_num=5, loss=5.490]Epoch 0:  72%|███████▏  | 186/258 [35:06<13:35, 11.32s/it, v_num=5, loss=5.260]Epoch 0:  72%|███████▏  | 187/258 [35:16<13:23, 11.32s/it, v_num=5, loss=5.260]Epoch 0:  72%|███████▏  | 187/258 [35:17<13:23, 11.32s/it, v_num=5, loss=5.490]Epoch 0:  73%|███████▎  | 188/258 [35:27<13:12, 11.32s/it, v_num=5, loss=5.490]Epoch 0:  73%|███████▎  | 188/258 [35:28<13:12, 11.32s/it, v_num=5, loss=5.260]Epoch 0:  73%|███████▎  | 189/258 [35:38<13:00, 11.32s/it, v_num=5, loss=5.260]Epoch 0:  73%|███████▎  | 189/258 [35:39<13:01, 11.32s/it, v_num=5, loss=5.040]Epoch 0:  74%|███████▎  | 190/258 [35:51<12:50, 11.32s/it, v_num=5, loss=5.040]Epoch 0:  74%|███████▎  | 190/258 [35:52<12:50, 11.33s/it, v_num=5, loss=5.240]Epoch 0:  74%|███████▍  | 191/258 [36:02<12:38, 11.32s/it, v_num=5, loss=5.240]Epoch 0:  74%|███████▍  | 191/258 [36:03<12:39, 11.33s/it, v_num=5, loss=5.180]Epoch 0:  74%|███████▍  | 192/258 [36:15<12:27, 11.33s/it, v_num=5, loss=5.180]Epoch 0:  74%|███████▍  | 192/258 [36:16<12:28, 11.33s/it, v_num=5, loss=5.140]Epoch 0:  75%|███████▍  | 193/258 [36:26<12:16, 11.33s/it, v_num=5, loss=5.140]Epoch 0:  75%|███████▍  | 193/258 [36:27<12:16, 11.34s/it, v_num=5, loss=5.300]Epoch 0:  75%|███████▌  | 194/258 [36:37<12:04, 11.33s/it, v_num=5, loss=5.300]Epoch 0:  75%|███████▌  | 194/258 [36:38<12:05, 11.33s/it, v_num=5, loss=4.860]Epoch 0:  76%|███████▌  | 195/258 [36:48<11:53, 11.33s/it, v_num=5, loss=4.860]Epoch 0:  76%|███████▌  | 195/258 [36:49<11:53, 11.33s/it, v_num=5, loss=5.490]Epoch 0:  76%|███████▌  | 196/258 [37:00<11:42, 11.33s/it, v_num=5, loss=5.490]Epoch 0:  76%|███████▌  | 196/258 [37:01<11:42, 11.33s/it, v_num=5, loss=5.580]Epoch 0:  76%|███████▋  | 197/258 [37:12<11:31, 11.33s/it, v_num=5, loss=5.580]Epoch 0:  76%|███████▋  | 197/258 [37:13<11:31, 11.34s/it, v_num=5, loss=5.030]Epoch 0:  77%|███████▋  | 198/258 [37:23<11:19, 11.33s/it, v_num=5, loss=5.030]Epoch 0:  77%|███████▋  | 198/258 [37:24<11:20, 11.34s/it, v_num=5, loss=5.730]Epoch 0:  77%|███████▋  | 199/258 [37:39<11:09, 11.36s/it, v_num=5, loss=5.730]Epoch 0:  77%|███████▋  | 199/258 [37:41<11:10, 11.36s/it, v_num=5, loss=5.380]Epoch 0:  78%|███████▊  | 200/258 [37:51<10:58, 11.36s/it, v_num=5, loss=5.380]Epoch 0:  78%|███████▊  | 200/258 [37:52<10:58, 11.36s/it, v_num=5, loss=5.080]Epoch 0:  78%|███████▊  | 201/258 [38:03<10:47, 11.36s/it, v_num=5, loss=5.080]Epoch 0:  78%|███████▊  | 201/258 [38:05<10:48, 11.37s/it, v_num=5, loss=5.270]Epoch 0:  78%|███████▊  | 202/258 [38:15<10:36, 11.36s/it, v_num=5, loss=5.270]Epoch 0:  78%|███████▊  | 202/258 [38:16<10:36, 11.37s/it, v_num=5, loss=5.320]Epoch 0:  79%|███████▊  | 203/258 [38:25<10:24, 11.36s/it, v_num=5, loss=5.320]Epoch 0:  79%|███████▊  | 203/258 [38:26<10:25, 11.36s/it, v_num=5, loss=5.040]Epoch 0:  79%|███████▉  | 204/258 [38:37<10:13, 11.36s/it, v_num=5, loss=5.040]Epoch 0:  79%|███████▉  | 204/258 [38:38<10:13, 11.36s/it, v_num=5, loss=5.150]Epoch 0:  79%|███████▉  | 205/258 [38:48<10:02, 11.36s/it, v_num=5, loss=5.150]Epoch 0:  79%|███████▉  | 205/258 [38:50<10:02, 11.37s/it, v_num=5, loss=5.330]Epoch 0:  80%|███████▉  | 206/258 [39:01<09:51, 11.37s/it, v_num=5, loss=5.330]Epoch 0:  80%|███████▉  | 206/258 [39:02<09:51, 11.37s/it, v_num=5, loss=5.480]Epoch 0:  80%|████████  | 207/258 [39:12<09:39, 11.37s/it, v_num=5, loss=5.480]Epoch 0:  80%|████████  | 207/258 [39:13<09:39, 11.37s/it, v_num=5, loss=5.240]Epoch 0:  81%|████████  | 208/258 [39:23<09:28, 11.36s/it, v_num=5, loss=5.240]Epoch 0:  81%|████████  | 208/258 [39:24<09:28, 11.37s/it, v_num=5, loss=5.220]Epoch 0:  81%|████████  | 209/258 [39:34<09:16, 11.36s/it, v_num=5, loss=5.220]Epoch 0:  81%|████████  | 209/258 [39:35<09:16, 11.36s/it, v_num=5, loss=5.030]Epoch 0:  81%|████████▏ | 210/258 [39:45<09:05, 11.36s/it, v_num=5, loss=5.030]Epoch 0:  81%|████████▏ | 210/258 [39:46<09:05, 11.36s/it, v_num=5, loss=5.430]Epoch 0:  82%|████████▏ | 211/258 [39:56<08:53, 11.36s/it, v_num=5, loss=5.430]Epoch 0:  82%|████████▏ | 211/258 [39:57<08:54, 11.36s/it, v_num=5, loss=5.460]Epoch 0:  82%|████████▏ | 212/258 [40:07<08:42, 11.36s/it, v_num=5, loss=5.460]Epoch 0:  82%|████████▏ | 212/258 [40:08<08:42, 11.36s/it, v_num=5, loss=4.900]Epoch 0:  83%|████████▎ | 213/258 [40:19<08:31, 11.36s/it, v_num=5, loss=4.900]Epoch 0:  83%|████████▎ | 213/258 [40:20<08:31, 11.36s/it, v_num=5, loss=5.320]Epoch 0:  83%|████████▎ | 214/258 [40:30<08:19, 11.36s/it, v_num=5, loss=5.320]Epoch 0:  83%|████████▎ | 214/258 [40:31<08:19, 11.36s/it, v_num=5, loss=5.270]Epoch 0:  83%|████████▎ | 215/258 [40:41<08:08, 11.36s/it, v_num=5, loss=5.270]Epoch 0:  83%|████████▎ | 215/258 [40:42<08:08, 11.36s/it, v_num=5, loss=5.440]Epoch 0:  84%|████████▎ | 216/258 [40:53<07:57, 11.36s/it, v_num=5, loss=5.440]Epoch 0:  84%|████████▎ | 216/258 [40:55<07:57, 11.37s/it, v_num=5, loss=5.250]Epoch 0:  84%|████████▍ | 217/258 [41:05<07:45, 11.36s/it, v_num=5, loss=5.250]Epoch 0:  84%|████████▍ | 217/258 [41:06<07:46, 11.37s/it, v_num=5, loss=5.080]Epoch 0:  84%|████████▍ | 218/258 [41:16<07:34, 11.36s/it, v_num=5, loss=5.080]Epoch 0:  84%|████████▍ | 218/258 [41:17<07:34, 11.36s/it, v_num=5, loss=5.030]Epoch 0:  85%|████████▍ | 219/258 [41:27<07:22, 11.36s/it, v_num=5, loss=5.030]Epoch 0:  85%|████████▍ | 219/258 [41:28<07:23, 11.36s/it, v_num=5, loss=5.250]Epoch 0:  85%|████████▌ | 220/258 [41:38<07:11, 11.36s/it, v_num=5, loss=5.250]Epoch 0:  85%|████████▌ | 220/258 [41:39<07:11, 11.36s/it, v_num=5, loss=5.050]Epoch 0:  86%|████████▌ | 221/258 [41:49<07:00, 11.36s/it, v_num=5, loss=5.050]Epoch 0:  86%|████████▌ | 221/258 [41:51<07:00, 11.36s/it, v_num=5, loss=5.030]Epoch 0:  86%|████████▌ | 222/258 [42:02<06:49, 11.36s/it, v_num=5, loss=5.030]Epoch 0:  86%|████████▌ | 222/258 [42:03<06:49, 11.37s/it, v_num=5, loss=5.550]Epoch 0:  86%|████████▋ | 223/258 [42:13<06:37, 11.36s/it, v_num=5, loss=5.550]Epoch 0:  86%|████████▋ | 223/258 [42:14<06:37, 11.37s/it, v_num=5, loss=5.110]Epoch 0:  87%|████████▋ | 224/258 [42:25<06:26, 11.36s/it, v_num=5, loss=5.110]Epoch 0:  87%|████████▋ | 224/258 [42:26<06:26, 11.37s/it, v_num=5, loss=5.240]Epoch 0:  87%|████████▋ | 225/258 [42:36<06:14, 11.36s/it, v_num=5, loss=5.240]Epoch 0:  87%|████████▋ | 225/258 [42:37<06:15, 11.37s/it, v_num=5, loss=5.210]Epoch 0:  88%|████████▊ | 226/258 [42:47<06:03, 11.36s/it, v_num=5, loss=5.210]Epoch 0:  88%|████████▊ | 226/258 [42:48<06:03, 11.37s/it, v_num=5, loss=5.220]Epoch 0:  88%|████████▊ | 227/258 [42:59<05:52, 11.37s/it, v_num=5, loss=5.220]Epoch 0:  88%|████████▊ | 227/258 [43:00<05:52, 11.37s/it, v_num=5, loss=5.120]Epoch 0:  88%|████████▊ | 228/258 [43:10<05:40, 11.36s/it, v_num=5, loss=5.120]Epoch 0:  88%|████████▊ | 228/258 [43:11<05:41, 11.37s/it, v_num=5, loss=5.460]Epoch 0:  89%|████████▉ | 229/258 [43:21<05:29, 11.36s/it, v_num=5, loss=5.460]Epoch 0:  89%|████████▉ | 229/258 [43:22<05:29, 11.36s/it, v_num=5, loss=4.760]Epoch 0:  89%|████████▉ | 230/258 [43:32<05:18, 11.36s/it, v_num=5, loss=4.760]Epoch 0:  89%|████████▉ | 230/258 [43:33<05:18, 11.36s/it, v_num=5, loss=5.380]Epoch 0:  90%|████████▉ | 231/258 [43:43<05:06, 11.36s/it, v_num=5, loss=5.380]Epoch 0:  90%|████████▉ | 231/258 [43:44<05:06, 11.36s/it, v_num=5, loss=5.650]Epoch 0:  90%|████████▉ | 232/258 [43:54<04:55, 11.36s/it, v_num=5, loss=5.650]Epoch 0:  90%|████████▉ | 232/258 [43:56<04:55, 11.36s/it, v_num=5, loss=4.720]Epoch 0:  90%|█████████ | 233/258 [44:07<04:44, 11.36s/it, v_num=5, loss=4.720]Epoch 0:  90%|█████████ | 233/258 [44:08<04:44, 11.37s/it, v_num=5, loss=5.050]Epoch 0:  91%|█████████ | 234/258 [44:19<04:32, 11.36s/it, v_num=5, loss=5.050]Epoch 0:  91%|█████████ | 234/258 [44:20<04:32, 11.37s/it, v_num=5, loss=5.220]Epoch 0:  91%|█████████ | 235/258 [44:30<04:21, 11.36s/it, v_num=5, loss=5.220]Epoch 0:  91%|█████████ | 235/258 [44:31<04:21, 11.37s/it, v_num=5, loss=5.220]Epoch 0:  91%|█████████▏| 236/258 [44:42<04:10, 11.37s/it, v_num=5, loss=5.220]Epoch 0:  91%|█████████▏| 236/258 [44:43<04:10, 11.37s/it, v_num=5, loss=5.220]Epoch 0:  92%|█████████▏| 237/258 [44:55<03:58, 11.37s/it, v_num=5, loss=5.220]Epoch 0:  92%|█████████▏| 237/258 [44:56<03:58, 11.38s/it, v_num=5, loss=4.950]Epoch 0:  92%|█████████▏| 238/258 [45:06<03:47, 11.37s/it, v_num=5, loss=4.950]Epoch 0:  92%|█████████▏| 238/258 [45:07<03:47, 11.38s/it, v_num=5, loss=4.930]Epoch 0:  93%|█████████▎| 239/258 [45:19<03:36, 11.38s/it, v_num=5, loss=4.930]Epoch 0:  93%|█████████▎| 239/258 [45:20<03:36, 11.38s/it, v_num=5, loss=5.320]Epoch 0:  93%|█████████▎| 240/258 [45:31<03:24, 11.38s/it, v_num=5, loss=5.320]Epoch 0:  93%|█████████▎| 240/258 [45:32<03:24, 11.39s/it, v_num=5, loss=4.880]Epoch 0:  93%|█████████▎| 241/258 [45:45<03:13, 11.39s/it, v_num=5, loss=4.880]Epoch 0:  93%|█████████▎| 241/258 [45:46<03:13, 11.40s/it, v_num=5, loss=5.210]Epoch 0:  94%|█████████▍| 242/258 [45:58<03:02, 11.40s/it, v_num=5, loss=5.210]Epoch 0:  94%|█████████▍| 242/258 [45:59<03:02, 11.40s/it, v_num=5, loss=4.690]Epoch 0:  94%|█████████▍| 243/258 [46:09<02:50, 11.40s/it, v_num=5, loss=4.690]Epoch 0:  94%|█████████▍| 243/258 [46:10<02:51, 11.40s/it, v_num=5, loss=4.900]Epoch 0:  95%|█████████▍| 244/258 [46:21<02:39, 11.40s/it, v_num=5, loss=4.900]Epoch 0:  95%|█████████▍| 244/258 [46:23<02:39, 11.41s/it, v_num=5, loss=5.410]Epoch 0:  95%|█████████▍| 245/258 [46:33<02:28, 11.40s/it, v_num=5, loss=5.410]Epoch 0:  95%|█████████▍| 245/258 [46:34<02:28, 11.41s/it, v_num=5, loss=4.760]Epoch 0:  95%|█████████▌| 246/258 [46:44<02:16, 11.40s/it, v_num=5, loss=4.760]Epoch 0:  95%|█████████▌| 246/258 [46:45<02:16, 11.40s/it, v_num=5, loss=5.390]Epoch 0:  96%|█████████▌| 247/258 [46:55<02:05, 11.40s/it, v_num=5, loss=5.390]Epoch 0:  96%|█████████▌| 247/258 [46:56<02:05, 11.40s/it, v_num=5, loss=5.560]Epoch 0:  96%|█████████▌| 248/258 [47:06<01:53, 11.40s/it, v_num=5, loss=5.560]Epoch 0:  96%|█████████▌| 248/258 [47:07<01:54, 11.40s/it, v_num=5, loss=5.010]Epoch 0:  97%|█████████▋| 249/258 [47:17<01:42, 11.39s/it, v_num=5, loss=5.010]Epoch 0:  97%|█████████▋| 249/258 [47:18<01:42, 11.40s/it, v_num=5, loss=5.340]Epoch 0:  97%|█████████▋| 250/258 [47:27<01:31, 11.39s/it, v_num=5, loss=5.340]Epoch 0:  97%|█████████▋| 250/258 [47:28<01:31, 11.39s/it, v_num=5, loss=4.840]Epoch 0:  97%|█████████▋| 251/258 [47:38<01:19, 11.39s/it, v_num=5, loss=4.840]Epoch 0:  97%|█████████▋| 251/258 [47:39<01:19, 11.39s/it, v_num=5, loss=5.110]Epoch 0:  98%|█████████▊| 252/258 [47:50<01:08, 11.39s/it, v_num=5, loss=5.110]Epoch 0:  98%|█████████▊| 252/258 [47:51<01:08, 11.39s/it, v_num=5, loss=5.410]Epoch 0:  98%|█████████▊| 253/258 [48:01<00:56, 11.39s/it, v_num=5, loss=5.410]Epoch 0:  98%|█████████▊| 253/258 [48:02<00:56, 11.40s/it, v_num=5, loss=5.200]Epoch 0:  98%|█████████▊| 254/258 [48:13<00:45, 11.39s/it, v_num=5, loss=5.200]Epoch 0:  98%|█████████▊| 254/258 [48:14<00:45, 11.39s/it, v_num=5, loss=5.220]Epoch 0:  99%|█████████▉| 255/258 [48:24<00:34, 11.39s/it, v_num=5, loss=5.220]Epoch 0:  99%|█████████▉| 255/258 [48:25<00:34, 11.39s/it, v_num=5, loss=4.980]Epoch 0:  99%|█████████▉| 256/258 [48:35<00:22, 11.39s/it, v_num=5, loss=4.980]Epoch 0:  99%|█████████▉| 256/258 [48:36<00:22, 11.39s/it, v_num=5, loss=5.270]Epoch 0: 100%|█████████▉| 257/258 [48:45<00:11, 11.38s/it, v_num=5, loss=5.270]Epoch 0: 100%|█████████▉| 257/258 [48:46<00:11, 11.39s/it, v_num=5, loss=5.650]Epoch 0: 100%|██████████| 258/258 [48:56<00:00, 11.38s/it, v_num=5, loss=5.650]Epoch 0: 100%|██████████| 258/258 [48:57<00:00, 11.39s/it, v_num=5, loss=5.350]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)

Validation: 0it [00:00, ?it/s][A
Validation:   0%|          | 0/25 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/25 [00:00<?, ?it/s][ATraceback (most recent call last):
  File "/home/sandy/miniconda3/envs/success/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py", line 42, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/sandy/miniconda3/envs/success/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/sandy/miniconda3/envs/success/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 973, in _run
    results = self._run_stage()
  File "/home/sandy/miniconda3/envs/success/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 1016, in _run_stage
    self.fit_loop.run()
  File "/home/sandy/miniconda3/envs/success/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 201, in run
    self.advance()
  File "/home/sandy/miniconda3/envs/success/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 354, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/sandy/miniconda3/envs/success/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 134, in run
    self.on_advance_end()
  File "/home/sandy/miniconda3/envs/success/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 248, in on_advance_end
    self.val_loop.run()
  File "/home/sandy/miniconda3/envs/success/lib/python3.9/site-packages/lightning/pytorch/loops/utilities.py", line 177, in _decorator
    return loop_run(self, *args, **kwargs)
  File "/home/sandy/miniconda3/envs/success/lib/python3.9/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 115, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx)
  File "/home/sandy/miniconda3/envs/success/lib/python3.9/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 375, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_kwargs.values())
  File "/home/sandy/miniconda3/envs/success/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py", line 291, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/sandy/miniconda3/envs/success/lib/python3.9/site-packages/lightning/pytorch/strategies/strategy.py", line 379, in validation_step
    return self.model.validation_step(*args, **kwargs)
  File "/mnt/c/Users/yihui/Desktop/Thesis/R2GenGPT/models/R2GenGPT.py", line 260, in validation_step
    outputs = self.llama_model.generate(
  File "/home/sandy/miniconda3/envs/success/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/sandy/miniconda3/envs/success/lib/python3.9/site-packages/transformers/generation/utils.py", line 1611, in generate
    return self.beam_search(
  File "/home/sandy/miniconda3/envs/success/lib/python3.9/site-packages/transformers/generation/utils.py", line 2962, in beam_search
    beam_outputs = beam_scorer.process(
  File "/home/sandy/miniconda3/envs/success/lib/python3.9/site-packages/transformers/generation/beam_search.py", line 238, in process
    if self._done[batch_idx]:
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/c/Users/yihui/Desktop/Thesis/R2GenGPT/train.py", line 54, in <module>
    main()
  File "/mnt/c/Users/yihui/Desktop/Thesis/R2GenGPT/train.py", line 50, in main
    train(args)
  File "/mnt/c/Users/yihui/Desktop/Thesis/R2GenGPT/train.py", line 40, in train
    trainer.fit(model, datamodule=dm)
  File "/home/sandy/miniconda3/envs/success/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "/home/sandy/miniconda3/envs/success/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py", line 66, in _call_and_handle_interrupt
    trainer._teardown()
  File "/home/sandy/miniconda3/envs/success/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 996, in _teardown
    self.strategy.teardown()
  File "/home/sandy/miniconda3/envs/success/lib/python3.9/site-packages/lightning/pytorch/strategies/strategy.py", line 472, in teardown
    _optimizers_to_device(self.optimizers, torch.device("cpu"))
  File "/home/sandy/miniconda3/envs/success/lib/python3.9/site-packages/lightning/fabric/utilities/optimizer.py", line 28, in _optimizers_to_device
    _optimizer_to_device(opt, device)
  File "/home/sandy/miniconda3/envs/success/lib/python3.9/site-packages/lightning/fabric/utilities/optimizer.py", line 34, in _optimizer_to_device
    optimizer.state[p] = apply_to_collection(v, Tensor, move_data_to_device, device, allow_frozen=True)
  File "/home/sandy/miniconda3/envs/success/lib/python3.9/site-packages/lightning_utilities/core/apply_func.py", line 54, in apply_to_collection
    return _apply_to_collection_slow(
  File "/home/sandy/miniconda3/envs/success/lib/python3.9/site-packages/lightning_utilities/core/apply_func.py", line 106, in _apply_to_collection_slow
    v = _apply_to_collection_slow(
  File "/home/sandy/miniconda3/envs/success/lib/python3.9/site-packages/lightning_utilities/core/apply_func.py", line 98, in _apply_to_collection_slow
    return function(data, *args, **kwargs)
  File "/home/sandy/miniconda3/envs/success/lib/python3.9/site-packages/lightning/fabric/utilities/apply_func.py", line 100, in move_data_to_device
    return apply_to_collection(batch, dtype=_TransferableDataType, function=batch_to)
  File "/home/sandy/miniconda3/envs/success/lib/python3.9/site-packages/lightning_utilities/core/apply_func.py", line 66, in apply_to_collection
    return function(data, *args, **kwargs)
  File "/home/sandy/miniconda3/envs/success/lib/python3.9/site-packages/lightning/fabric/utilities/apply_func.py", line 94, in batch_to
    data_output = data.to(device, **kwargs)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

